#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Sistema HP - Extrator Completo Integrado
Combina extra√ß√£o de dados de produtos + extra√ß√£o de reviews
Baseado nos c√≥digos originais do usu√°rio

MELHORIAS IMPLEMENTADAS:
- Corre√ß√£o na coleta de links de produtos na busca
- Seletores aprimorados para encontrar elementos poly-component__title
- L√≥gica de espera melhorada para carregamento de p√°ginas
- M√©todo alternativo de coleta quando os seletores principais falham
- Debug detalhado para acompanhar o processo de coleta
- Fun√ß√£o de teste espec√≠fica para validar a coleta de links
"""

import time
import sys
import os
import json
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
from webdriver_manager.chrome import ChromeDriverManager
import shutil

# Adicionar src ao path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

def criar_pasta_dados():
    """Cria a estrutura de pastas para salvar os dados extra√≠dos"""
    try:
        # Caminho base para a pasta data DENTRO de Selenium
        base_path = os.path.join(os.path.dirname(__file__), 'data')
        
        # Criar pasta principal se n√£o existir
        if not os.path.exists(base_path):
            os.makedirs(base_path)
        
        # Criar pasta espec√≠fica para dados extra√≠dos
        dados_path = os.path.join(base_path, 'dados_extraidos')
        if not os.path.exists(dados_path):
            os.makedirs(dados_path)
        
        # Criar subpastas por tipo de extra√ß√£o
        subpastas = ['lote', 'tipo_especifico', 'produto_especifico']
        for subpasta in subpastas:
            subpasta_path = os.path.join(dados_path, subpasta)
            if not os.path.exists(subpasta_path):
                os.makedirs(subpasta_path)
        
        print(f"Estrutura de pastas criada em: {dados_path}")
        return dados_path
        
    except Exception as e:
        print(f"Erro ao criar estrutura de pastas: {e}")
        # Fallback: usar diret√≥rio atual
        return os.getcwd()

class MercadoLivreReviewsExtractor:
    def __init__(self, driver, headless=False):
        """Inicializa o extrator de reviews usando o driver existente"""
        self.driver = driver
        self.headless = headless
    
    def extract_reviews(self, product_id, max_reviews=None):
        """
        Extrai reviews de um produto espec√≠fico
        
        Args:
            product_id (str): ID do produto (ex: MLB22843600)
            max_reviews (int): N√∫mero m√°ximo de reviews a extrair (None = todos)
        
        Returns:
            dict: Dados extra√≠dos dos reviews
        """
        print(f"üîç Iniciando extra√ß√£o de reviews para produto: {product_id}")
        
        # Construir URL com todos os par√¢metros necess√°rios para a vers√£o mobile (funcional)
        url = f"https://www.mercadolivre.com.br/noindex/catalog/reviews/{product_id}?noIndex=true&access=view_all&modal=true&controlled=true&show_fae=true&brandId=49944&source_platform=/web/mobile&device_id_variant=ff846adc-7561-4cd6-84d5-2d847aa9dd1f"
        
        try:
            print(f"üåê Acessando reviews: {url}")
            self.driver.get(url)
            
            # Aguardar carregamento inicial
            print("‚è≥ Aguardando carregamento inicial...")
            time.sleep(3)
            
            # Extrair dados gerais
            general_data = self.extract_general_data()
            
            # Extrair resumo de IA
            ai_summary = self.extract_ai_summary()
            
            # Extrair avalia√ß√µes por caracter√≠sticas
            characteristics_ratings = self.extract_characteristics_ratings()
            
            # Extrair reviews individuais com scroll
            reviews = self.extract_individual_reviews(max_reviews)
            
            # Compilar dados finais
            result = {
                "product_id": product_id,
                "extraction_timestamp": datetime.now().isoformat(),
                "url": url,
                "general_data": general_data,
                "ai_summary": ai_summary,
                "characteristics_ratings": characteristics_ratings,
                "reviews": reviews,
                "total_reviews_extracted": len(reviews)
            }
            
            print(f"‚úÖ Extra√ß√£o de reviews conclu√≠da! {len(reviews)} reviews extra√≠dos")
            return result
            
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o de reviews: {e}")
            return None
    
    def extract_general_data(self):
        """Extrai dados gerais da p√°gina de reviews"""
        print("üìä Extraindo dados gerais dos reviews...")
        
        general_data = {}
        
        try:
            rating_elem = self.driver.find_element(By.CSS_SELECTOR, ".ui-review-capability__rating__average")
            general_data["average_rating"] = float(rating_elem.text.strip())
        except NoSuchElementException:
            general_data["average_rating"] = None
        
        try:
            total_elem = self.driver.find_element(By.CSS_SELECTOR, ".ui-review-capability__rating__label")
            total_text = total_elem.text.strip()
            total_match = re.search(r'(\d+)', total_text)
            if total_match:
                general_data["total_reviews"] = int(total_match.group(1))
        except NoSuchElementException:
            general_data["total_reviews"] = None
        
        return general_data
    
    def extract_ai_summary(self):
        """Extrai resumo de opini√µes gerado por IA"""
        print("ü§ñ Extraindo resumo de IA...")
        
        try:
            summary_container = self.driver.find_element(By.CSS_SELECTOR, "div[data-testid='summary-component']")
            
            summary_elem = summary_container.find_element(By.CSS_SELECTOR, "p.ui-review-capability__summary__plain_text__summary_container")
            summary_text = summary_elem.text.strip()
            
            # Busca o bot√£o de like DENTRO do container do resumo
            likes_elem = summary_container.find_element(By.CSS_SELECTOR, "button[data-testid='like-button'] p")
            likes = int(likes_elem.text.strip())
            
            return {
                "summary": summary_text,
                "likes": likes,
                "available": True
            }
        except NoSuchElementException:
            return {
                "summary": None,
                "likes": 0,
                "available": False
            }
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao extrair resumo de IA: {e}")
            return { "summary": None, "likes": 0, "available": False }

    def extract_characteristics_ratings(self):
        """Extrai avalia√ß√µes por caracter√≠sticas"""
        print("üìã Extraindo avalia√ß√µes por caracter√≠sticas...")
        
        characteristics = {}
        
        try:
            table_rows = self.driver.find_elements(By.CSS_SELECTOR, "tr.ui-review-capability-categories__mobile--row")
            
            for row in table_rows:
                try:
                    name_elem = row.find_element(By.CSS_SELECTOR, "td:first-child")
                    characteristic_name = name_elem.text.strip()
                    
                    # Pega a nota pelo texto de acessibilidade, que √© mais confi√°vel
                    rating_text_elem = row.find_element(By.CSS_SELECTOR, "p.andes-visually-hidden")
                    rating_text = rating_text_elem.get_attribute('textContent').strip()
                    
                    # Extrai o n√∫mero do texto "Avalia√ß√£o 4.8 de 5"
                    match = re.search(r'(\d+\.?\d*)', rating_text)
                    if match:
                        characteristics[characteristic_name] = float(match.group(1))
                    
                except Exception:
                    continue
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao buscar tabela de caracter√≠sticas: {e}")
        
        return characteristics
    
    def extract_individual_reviews(self, max_reviews=None):
        """Extrai reviews individuais com scroll autom√°tico inteligente"""
        print("üìù Extraindo reviews individuais...")
        
        self.scroll_to_load_all_reviews()
        
        review_elements = self.driver.find_elements(By.CSS_SELECTOR, "article.ui-review-capability-comments__comment")
        
        if max_reviews:
            review_elements = review_elements[:max_reviews]
        
        print(f"üìù Processando {len(review_elements)} reviews encontrados...")
        
        reviews = []
        for i, review_elem in enumerate(review_elements):
            review_data = self.extract_single_review(review_elem, i + 1)
            if review_data:
                reviews.append(review_data)
        
        return reviews
    
    def scroll_to_load_all_reviews(self):
        """Scroll inteligente para carregar todos os reviews dispon√≠veis"""
        print("üîÑ Iniciando scroll inteligente...")
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        attempts = 0
        
        while attempts < 3:
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            
            if new_height == last_height:
                attempts += 1
                print(f"   Altura da p√°gina n√£o mudou. Tentativa {attempts}/3.")
            else:
                last_height = new_height
                attempts = 0
        
        print("‚úÖ Scroll inteligente conclu√≠do!")

    def extract_single_review(self, review_elem, review_number):
        """Extrai dados de um review individual"""
        review_data = {
            "review_number": review_number,
            "rating": None,
            "date": None,
            "text": "Sem texto.",
            "likes": 0,
            "images": []
        }
        
        try:
            # Extrair rating
            try:
                rating_text_elem = review_elem.find_element(By.CSS_SELECTOR, "p.andes-visually-hidden")
                rating_text = rating_text_elem.get_attribute('textContent').strip()
                match = re.search(r'(\d+)', rating_text)
                if match:
                    review_data["rating"] = int(match.group(1))
            except NoSuchElementException:
                pass
            
            # Extrair data
            try:
                date_elem = review_elem.find_element(By.CSS_SELECTOR, ".ui-review-capability-comments__comment__date")
                review_data["date"] = date_elem.text.strip()
            except NoSuchElementException:
                pass
            
            # Extrair texto
            try:
                text_elem = review_elem.find_element(By.CSS_SELECTOR, ".ui-review-capability-comments__comment__content")
                text_content = text_elem.text.strip()
                if text_content:
                    review_data["text"] = text_content
            except NoSuchElementException:
                pass
            
            # Extrair imagens
            try:
                image_elements = review_elem.find_elements(By.CSS_SELECTOR, ".ui-review-capability-carousel-mobile__img")
                if image_elements:
                    image_urls = [img.get_attribute("src") for img in image_elements if img.get_attribute("src")]
                    review_data["images"] = image_urls
            except NoSuchElementException:
                pass

            # Extrair likes
            try:
                like_button = review_elem.find_element(By.CSS_SELECTOR, "button[data-testid='like-button']")
                likes_elem = like_button.find_elements(By.TAG_NAME, "p")[-1]
                review_data["likes"] = int(likes_elem.text.strip())
            except (NoSuchElementException, IndexError):
                pass
            
            # Renomear chaves para o formato final desejado
            review_data["image_count"] = len(review_data["images"])
            review_data["has_images"] = True if review_data["image_count"] > 0 else False
            
            return review_data
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao extrair dados do review #{review_number}: {e}")
            return None

def setup_browser_session():
    """Configura navegador e aguarda login - detecta automaticamente Chrome ou Edge"""
    try:
        print("Detectando navegador dispon√≠vel...")
        
        # Tentar Chrome primeiro
        chrome_paths = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe"
        ]
        
        chrome_available = any(os.path.exists(path) for path in chrome_paths)
        
        if chrome_available:
            print("Chrome encontrado! Usando Chrome...")
            chrome_options = ChromeOptions()
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)
        else:
            print("Chrome n√£o encontrado. Usando Edge...")
            edge_options = EdgeOptions()
            edge_options.add_argument("--no-sandbox")
            edge_options.add_argument("--disable-dev-shm-usage")
            edge_options.add_argument("--disable-blink-features=AutomationControlled")
            edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            edge_options.add_experimental_option('useAutomationExtension', False)
            
            driver = webdriver.Edge(options=edge_options)
        
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        print("Navegando para MercadoLivre...")
        driver.get("https://www.mercadolivre.com.br")
        
        print("\n" + "="*60)
        print("FA√áA LOGIN NO MERCADOLIVRE")
        print("="*60)
        print("1. Clique em 'Entrar' no canto superior direito")
        print("2. Digite seu email/usu√°rio e senha")
        print("3. Complete o login (incluindo verifica√ß√µes se houver)")
        print("4. Aguarde aparecer seu nome no canto superior direito")
        print("5. Pressione ENTER neste terminal quando terminar")
        print("="*60)
        
        input("\nPressione ENTER ap√≥s fazer login completo...")
        
        print("Sess√£o configurada! Navegador permanecer√° ativo.")
        return driver
        
    except Exception as e:
        print(f"Erro ao configurar navegador: {e}")
        return None

def is_error_page(driver):
    """
    Verifica se a p√°gina atual √© uma p√°gina de erro/not found
    """
    try:
        current_url = driver.current_url.lower()
        page_title = driver.title.lower()

        print(f"üîç DEBUG is_error_page:")
        print(f"   URL: {current_url}")
        print(f"   T√≠tulo: {page_title}")

        # Verifica√ß√µes espec√≠ficas para p√°ginas de erro reais do ML
        error_indicators = [
            # URLs que definitivamente indicam erro
            "error" in current_url,
            "not-found" in current_url,
            "pagina-nao-encontrada" in current_url,
            # T√≠tulos espec√≠ficos de erro
            "p√°gina n√£o encontrada" in page_title,
            "produto n√£o encontrado" in page_title,
            "erro" in page_title and "404" in page_title,
            # Elementos espec√≠ficos de erro com texto espec√≠fico
            len(driver.find_elements(By.CSS_SELECTOR, ".ui-empty-state__title")) > 0 and
            any("n√£o encontrado" in elem.text.lower() or "erro" in elem.text.lower()
                for elem in driver.find_elements(By.CSS_SELECTOR, ".ui-empty-state__title")),
            # Combina√ß√£o de elementos t√≠picos de erro
            len(driver.find_elements(By.CSS_SELECTOR, ".ui-empty-state")) > 0 and
            len(driver.find_elements(By.CSS_SELECTOR, ".ui-empty-state__icon")) > 0 and
            "produto" not in driver.page_source.lower()
        ]

        # Se encontrou indicadores claros de erro, retorna True
        if any(error_indicators):
            print(f"‚ùå P√°gina de erro detectada (indicadores claros)")
            return True

        # Verifica√ß√£o adicional: se n√£o h√° elementos t√≠picos de produto, pode ser erro
        product_indicators = [
            ".ui-pdp-title",  # T√≠tulo do produto
            ".ui-pdp-price",  # Pre√ßo do produto
            ".ui-pdp-seller", # Informa√ß√µes do vendedor
            ".ui-pdp-description", # Descri√ß√£o
            ".ui-pdp-gallery", # Galeria de imagens
            "poly-component__title", # T√≠tulo alternativo
            "[data-testid='product-title']", # T√≠tulo moderno
            ".andes-card", # Estrutura moderna de produto
            ".ui-vip-core", # Produto VIP
            ".ui-pdp-container", # Container principal do produto
            ".ui-pdp-header", # Cabe√ßalho do produto
            ".ui-pdp-main", # √Årea principal do produto
            "[class*='product']", # Qualquer classe com 'product'
            "h1", # T√≠tulo principal (pode ser produto)
        ]

        has_product_content = any(
            len(driver.find_elements(By.CSS_SELECTOR, selector)) > 0
            for selector in product_indicators
        )

        print(f"   ‚úÖ Tem conte√∫do de produto: {has_product_content}")

        # Verifica√ß√£o adicional: tamanho do conte√∫do da p√°gina
        page_source_length = len(driver.page_source)
        print(f"   üìÑ Tamanho da p√°gina: {page_source_length} caracteres")

        # Se n√£o h√° conte√∫do de produto E p√°gina √© muito pequena (< 5000 chars), pode ser erro
        if not has_product_content and page_source_length < 5000:
            error_elements = driver.find_elements(By.CSS_SELECTOR, ".ui-empty-state, .not-found-page, .error-page")
            print(f"   ‚ö†Ô∏è Elementos de erro encontrados: {len(error_elements)}")
            if error_elements:
                print(f"‚ùå P√°gina de erro detectada (sem conte√∫do de produto + p√°gina pequena)")
                return True

        # Se h√° conte√∫do de produto, considere p√°gina v√°lida mesmo com elementos de erro
        if has_product_content:
            print(f"‚úÖ P√°gina v√°lida detectada (tem conte√∫do de produto)")
            return False

        # Se n√£o h√° conte√∫do de produto mas p√°gina √© grande, pode ser produto com estrutura diferente
        if page_source_length > 10000:  # P√°gina grande provavelmente tem conte√∫do
            print(f"‚úÖ P√°gina v√°lida detectada (p√°gina grande, provavelmente produto)")
            return False

        print(f"‚ö†Ô∏è P√°gina suspeita detectada")
        return False

    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao verificar p√°gina de erro: {e}")
        return False

def extract_javascript_data_advanced(driver, product_url_or_code):
    """
    Extrator JavaScript avan√ßado baseado em todos os aprendizados.
    Aceita URL completa ou c√≥digo do produto.
    """

    try:
        # Verificar se √© c√≥digo ou URL
        if product_url_or_code and not product_url_or_code.startswith('http'):
            # √â um c√≥digo de produto
            product_url = build_product_url(product_url_or_code)
            print(f"üîç Extraindo dados JavaScript avan√ßados do c√≥digo: {product_url_or_code}")
        else:
            # √â uma URL completa
            product_url = product_url_or_code
            print(f"üîç Extraindo dados JavaScript avan√ßados de: {product_url}")

        if not product_url:
            print("‚ùå Erro: N√£o foi poss√≠vel construir URL do produto")
            return None

        driver.get(product_url)
        
        # Aguardar p√°gina carregar
        print("‚è≥ Aguardando p√°gina carregar...")
        time.sleep(5)

        # Verificar se √© p√°gina de erro ANTES de tentar extra√ß√£o
        if is_error_page(driver):
            print("‚ùå P√°gina de erro detectada - produto n√£o existe ou foi removido")
            print(f"   URL: {product_url}")
            print(f"   T√≠tulo: {driver.title}")
            return None
        
        produto_completo = {
            'id': '',
            'titulo': '',
            'link': product_url,
            'preco': '',
            'preco_original': '',
            'desconto': '',
            'vendedor': '',
            'seller_id': '',
            'reputation_level': '',
            'power_seller_status': '',
            'rating_medio': 0.0,
            'total_reviews': 0,
            'rating_5_estrelas': 0,
            'rating_4_estrelas': 0,
            'rating_3_estrelas': 0,
            'rating_2_estrelas': 0,
            'rating_1_estrela': 0,
            'reviews_com_texto': 0,
            'reviews_com_imagens': 0,
            'imagem_url': '',
            'frete_gratis': False,
            'categoria': '',
            'marca': '',
            'condicao': 'Novo',
            'disponibilidade': '',
            'quantidade_vendida': '',
            'reviews_detalhadas': [],
            'dados_brutos': {}
        }
        
        # 1. EXTRAIR JSON-LD (Dados Estruturados)
        print("üìä 1. Extraindo dados JSON-LD...")
        json_ld_data = extract_json_ld(driver)
        if json_ld_data:
            populate_from_json_ld(produto_completo, json_ld_data)
        
        # 2. EXTRAIR MELIDATA (Analytics + Dados Completos)
        print("üìä 2. Extraindo dados MeliData...")
        melidata_info = extract_melidata_advanced(driver)
        if melidata_info:
            populate_from_melidata(produto_completo, melidata_info)
        
        # 3. EXTRAIR DADOS DO WINDOW (Estados JavaScript)
        print("üìä 3. Extraindo dados do Window...")
        window_data = extract_window_data(driver)
        if window_data:
            populate_from_window_data(produto_completo, window_data)
        
        # 4. EXTRAIR CARACTER√çSTICAS DO PRODUTO (Marca, Modelo, etc.)
        print("üìä 4. Extraindo caracter√≠sticas do produto...")
        extract_product_characteristics(driver, produto_completo)
        
        # 5. EXTRAIR RATING DETALHADO POR ESTRELAS
        print("üìä 5. Extraindo rating detalhado por estrelas...")
        extract_detailed_rating(driver, produto_completo)
        
        # 6. Extrair descri√ß√£o do produto
        print("üìä 6. Extraindo descri√ß√£o do produto...")
        descricao = extract_product_description(driver)
        produto_completo.update(descricao)
        
        # 7. EXTRAIR QUANTIDADE VENDIDA
        print("üìä 7. Extraindo quantidade vendida...")
        extract_sold_quantity(driver, produto_completo)
        
        # 8. EXTRAIR DADOS ADICIONAIS DO DOM
        print("üìä 8. Extraindo dados adicionais do DOM...")
        extract_additional_dom_data(driver, produto_completo)
        
        # 9. EXTRAIR REVIEWS DO PRODUTO E ADICIONAR COMO 'todos_reviews'
        print("üìä 9. Extraindo reviews do produto...")
        reviews_extractor = MercadoLivreReviewsExtractor(driver)
        
        # Extrair ID do produto da URL ou usar c√≥digo diretamente
        product_id = extract_product_id_from_url(product_url)
        if not product_id and product_url_or_code and not product_url_or_code.startswith('http'):
            # Se temos um c√≥digo, extrair o ID dele
            product_id = product_url_or_code.replace('MLB', '').replace('MLU', '').replace('MLC', '').replace('MCO', '').replace('MLV', '').replace('MPE', '').replace('MPT', '').replace('MLM', '')

        if product_id:
            reviews_data = reviews_extractor.extract_reviews(product_id, max_reviews=50)  # Limitar a 50 reviews por produto
            if reviews_data:
                # Adicionar reviews como 'todos_reviews' (formato unificado)
                reviews_com_info = []
                for review in reviews_data['reviews']:
                    review['produto_id'] = produto_completo.get('id', '')
                    review['produto_titulo'] = produto_completo.get('titulo', '')
                    review['produto_url'] = produto_completo.get('link', '')
                    reviews_com_info.append(review)
                
                produto_completo['todos_reviews'] = reviews_com_info
                produto_completo['reviews_com_texto'] = len([r for r in reviews_data['reviews'] if r.get('text') and r['text'] != 'Sem texto.'])
                produto_completo['reviews_com_imagens'] = len([r for r in reviews_data['reviews'] if r.get('has_images', False)])
                produto_completo['ai_summary'] = reviews_data.get('ai_summary', {})
                produto_completo['characteristics_ratings'] = reviews_data.get('characteristics_ratings', {})
                print(f"‚úÖ Reviews extra√≠dos: {len(produto_completo['todos_reviews'])} reviews")
            else:
                produto_completo['todos_reviews'] = []
                print("‚ö†Ô∏è N√£o foi poss√≠vel extrair reviews para este produto")
        else:
            produto_completo['todos_reviews'] = []
            print("‚ö†Ô∏è N√£o foi poss√≠vel extrair ID do produto da URL/c√≥digo")
        
        # Salvar dados brutos para debug
        produto_completo['dados_brutos'] = {
            'json_ld': json_ld_data,
            'melidata': melidata_info,
            'window_data': window_data,
            'timestamp': datetime.now().isoformat()
        }
        
        # Debug final: resumo do produto extra√≠do
        print(f"‚úÖ Extra√ß√£o completa finalizada! Produto: {produto_completo.get('titulo', 'N/A')}")
        print("üîç DEBUG: Resumo do produto extra√≠do:")
        print(f"   üì¶ ID: {produto_completo.get('id', 'N/A')}")
        print(f"   üí∞ Pre√ßo: {produto_completo.get('preco', 'N/A')}")
        print(f"   üè™ Vendedor: {produto_completo.get('vendedor', 'N/A')}")
        print(f"   ‚≠ê Rating m√©dio: {produto_completo.get('rating_medio', 'N/A')}")
        print(f"   üí¨ Reviews: {produto_completo.get('total_reviews', 'N/A')}")
        print(f"   üìù Reviews detalhadas: {len(produto_completo.get('reviews_detalhadas', []))}")
        print(f"   üöö Frete gr√°tis: {produto_completo.get('frete_gratis', 'N/A')}")
        print(f"   üè∑Ô∏è Marca: {produto_completo.get('marca', 'N/A')}")
        print(f"   üîß Modelo: {produto_completo.get('modelo', 'N/A')}")
        print(f"   üì¶ Quantidade vendida: {produto_completo.get('quantidade_vendida', 'N/A')}")
        
        return produto_completo
        
    except Exception as e:
        print(f"‚ùå Erro ao extrair dados JavaScript: {e}")
        return None

def extract_product_id_from_url(url):
    """Extrai o ID do produto da URL"""
    try:
        # Padr√µes comuns de URLs do MercadoLivre
        patterns = [
            r'/MLB-(\d+)',
            r'/p/MLB(\d+)',
            r'MLB(\d+)',
            r'/(\d+)-'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return f"MLB{match.group(1)}"
        
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao extrair ID da URL: {e}")
        return None

def extract_json_ld(driver):
    """Extrai dados JSON-LD estruturados"""
    try:
        json_ld_script = driver.find_element(By.CSS_SELECTOR, 'script[type="application/ld+json"]')
        json_ld_data = json.loads(json_ld_script.get_attribute('textContent'))
        print("‚úÖ Dados JSON-LD extra√≠dos com sucesso")
        return json_ld_data
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao extrair JSON-LD: {e}")
        return None

def extract_melidata_advanced(driver):
    """Extrai dados MeliData usando SDK"""
    try:
        melidata_script = """
        try {
            var melitrackerData = {};
            
            var scripts = document.getElementsByTagName('script');
            for (var i = 0; i < scripts.length; i++) {
                var content = scripts[i].textContent;
                if (content.includes('melidata("add", "event_data"')) {
                    var matches = content.match(/melidata\\("add", "event_data", ({.*?})\\)/g);
                    if (matches) {
                        for (var j = 0; j < matches.length; j++) {
                            try {
                                var dataMatch = matches[j].match(/melidata\\("add", "event_data", ({.*?})\\)/);
                                if (dataMatch) {
                                    var eventData = JSON.parse(dataMatch[1]);
                                    Object.assign(melitrackerData, eventData);
                                }
                            } catch(e) { console.log("Erro parsing melidata:", e); }
                        }
                    }
                }
            }
            
            if (typeof window.melidata_namespace !== 'undefined') {
                melitrackerData.melidata_namespace_available = true;
                melitrackerData.melidata_utils = window.melidata_namespace.utils ? 'available' : 'not_available';
            }
            
            if (typeof window.__PRELOADED_STATE__ !== 'undefined') {
                melitrackerData.__PRELOADED_STATE__ = window.__PRELOADED_STATE__;
            }
            
            return melitrackerData;
            
        } catch(e) {
            return { error: e.toString() };
        }
        """
        
        melidata_info = driver.execute_script(melidata_script)
        
        if melidata_info and not melidata_info.get('error'):
            print(f"‚úÖ Dados MeliData extra√≠dos: {len(melidata_info)} campos")
            return melidata_info
        else:
            print(f"‚ö†Ô∏è Erro ao extrair MeliData: {melidata_info.get('error', 'Dados n√£o encontrados')}")
            return None
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao executar script MeliData: {e}")
        return None

def extract_window_data(driver):
    """Extrai dados de objetos globais do window"""
    try:
        window_script = """
        return {
            location_href: window.location.href,
            location_pathname: window.location.pathname,
            document_title: document.title,
            melidata_available: typeof window.melidata !== 'undefined',
            jquery_available: typeof window.$ !== 'undefined',
            react_available: typeof window.React !== 'undefined'
        };
        """
        
        window_data = driver.execute_script(window_script)
        print("‚úÖ Dados do Window extra√≠dos")
        return window_data
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao extrair dados do Window: {e}")
        return None

def populate_from_json_ld(produto, json_ld_data):
    """Popula dados do produto a partir do JSON-LD"""
    try:
        if not json_ld_data:
            return
        
        if 'name' in json_ld_data:
            produto['titulo'] = json_ld_data['name']
        
        if 'image' in json_ld_data:
            produto['imagem_url'] = json_ld_data['image']
        
        if 'brand' in json_ld_data:
            produto['marca'] = json_ld_data['brand']
        
        if 'sku' in json_ld_data:
            produto['id'] = json_ld_data['sku']
        
        if 'description' in json_ld_data:
            produto['descricao'] = json_ld_data['description']
        
        if 'offers' in json_ld_data:
            offers = json_ld_data['offers']
            if 'price' in offers:
                produto['preco'] = str(offers['price'])
            
            if 'availability' in offers:
                produto['disponibilidade'] = offers['availability']
        
        if 'aggregateRating' in json_ld_data:
            rating = json_ld_data['aggregateRating']
            if 'ratingValue' in rating:
                produto['rating_medio'] = float(rating['ratingValue'])
            if 'ratingCount' in rating:
                produto['total_reviews'] = int(rating['ratingCount'])
        
        print("‚úÖ Dados JSON-LD aplicados ao produto")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao aplicar dados JSON-LD: {e}")

def populate_from_melidata(produto, melidata_info):
    """Popula dados do produto a partir do MeliData"""
    try:
        if not melidata_info:
            return
        
        if 'catalog_product_id' in melidata_info:
            produto['id'] = melidata_info['catalog_product_id']
        
        if 'seller_id' in melidata_info:
            produto['seller_id'] = str(melidata_info['seller_id'])
        
        if 'seller_name' in melidata_info:
            produto['vendedor'] = melidata_info['seller_name']
        
        if 'price' in melidata_info:
            produto['preco'] = str(melidata_info['price'])
        
        if 'free_shipping' in melidata_info:
            produto['frete_gratis'] = melidata_info['free_shipping']
        
        if 'reputation_level' in melidata_info:
            produto['reputation_level'] = melidata_info['reputation_level']
        
        if 'power_seller_status' in melidata_info:
            produto['power_seller_status'] = melidata_info['power_seller_status']
        
        if 'reviews' in melidata_info:
            reviews_data = melidata_info['reviews']
            if 'rate' in reviews_data:
                produto['rating_medio'] = float(reviews_data['rate'])
            if 'count' in reviews_data:
                produto['total_reviews'] = int(reviews_data['count'])
        
        print("‚úÖ Dados MeliData aplicados ao produto")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao aplicar dados MeliData: {e}")

def populate_from_window_data(produto, window_data):
    """Popula dados do produto a partir dos dados do window"""
    try:
        if not window_data:
            return
        
        if 'document_title' in window_data:
            produto['titulo'] = window_data['document_title']
        
        if 'location_href' in window_data:
            produto['link'] = window_data['location_href']
        
        print("‚úÖ Dados do Window aplicados ao produto")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao aplicar dados do Window: {e}")

def extract_product_characteristics(driver, produto_completo):
    """Extrai caracter√≠sticas espec√≠ficas do produto"""
    try:
        print("üîç DEBUG: Buscando caracter√≠sticas do produto...")
        
        characteristics_selectors = [
            '.ui-pdp-container__row--technical-specifications',
            '.ui-vpp-highlighted-specs',
            '.ui-vpp-striped-specs__table',
            '.andes-table',
            '[class*="spec"]'
        ]
        
        characteristics_section = None
        for selector in characteristics_selectors:
            try:
                characteristics_section = driver.find_element(By.CSS_SELECTOR, selector)
                print(f"‚úÖ Se√ß√£o de caracter√≠sticas encontrada: {selector}")
                break
            except:
                continue
        
        if characteristics_section:
            characteristics = {}
            
            try:
                table_selectors = [
                    '.ui-vpp-striped-specs__table table',
                    '.andes-table',
                    'table.andes-table',
                    'table'
                ]
                
                table = None
                for table_sel in table_selectors:
                    try:
                        table = characteristics_section.find_element(By.CSS_SELECTOR, table_sel)
                        print(f"‚úÖ Tabela de caracter√≠sticas encontrada com: {table_sel}")
                        break
                    except:
                        continue
                
                if not table:
                    table = characteristics_section
                
                rows_selectors = [
                    'tr.andes-table__row.ui-vpp-striped-specs__row',
                    'tr.andes-table__row',
                    'tr.ui-vpp-striped-specs__row',
                    'tr'
                ]
                
                rows = []
                for row_sel in rows_selectors:
                    try:
                        rows = table.find_elements(By.CSS_SELECTOR, row_sel)
                        if rows:
                            print(f"‚úÖ {len(rows)} linhas de caracter√≠sticas encontradas com: {row_sel}")
                            break
                    except:
                        continue
                
                for i, row in enumerate(rows[:20]):
                    try:
                        key_selectors = [
                            'th .andes-table__header__container',
                            '.andes-table__header__container',
                            'th',
                            '.andes-table__header'
                        ]
                        
                        value_selectors = [
                            'td .andes-table__column--value',
                            '.andes-table__column--value',
                            'td span',
                            'td',
                            '.andes-table__column'
                        ]
                        
                        key = None
                        value = None
                        
                        for key_sel in key_selectors:
                            try:
                                key_elem = row.find_element(By.CSS_SELECTOR, key_sel)
                                key_text = key_elem.text.strip()
                                if key_text and len(key_text) > 1:
                                    key = key_text.lower()
                                    break
                            except:
                                continue
                        
                        for value_sel in value_selectors:
                            try:
                                value_elem = row.find_element(By.CSS_SELECTOR, value_sel)
                                value_text = value_elem.text.strip()
                                if value_text and len(value_text) > 0:
                                    value = value_text
                                    break
                            except:
                                continue
                        
                        if not key or not value:
                            continue
                        
                        # Mapear caracter√≠sticas importantes
                        if 'marca' in key:
                            produto_completo['marca'] = value
                        elif 'modelo' in key and 'alfanum√©rico' not in key:
                            produto_completo['modelo'] = value
                        elif 'modelo alfanum√©rico' in key or 'alfanum√©rico' in key:
                            produto_completo['modelo_alfanumerico'] = value
                        elif any(word in key for word in ['rendimento', 'p√°ginas', 'pagina']):
                            produto_completo['rendimento_paginas'] = value
                        elif 'linha' in key:
                            produto_completo['linha'] = value
                        elif 'tipo de cartucho' in key or ('tipo' in key and 'cartucho' in key):
                            produto_completo['tipo_cartucho'] = value
                        elif 'cor da tinta' in key or ('cor' in key and 'tinta' in key):
                            produto_completo['cor_tinta'] = value
                        elif 'conte√∫do total em volume' in key or ('volume' in key and 'total' in key):
                            produto_completo['volume'] = value
                        elif 'tipo de tinta' in key:
                            produto_completo['tipo_tinta'] = value
                        elif '√© recarreg√°vel' in key or 'recarreg√°vel' in key:
                            produto_completo['recarregavel'] = value
                        
                        characteristics[key] = value
                                
                    except Exception as e:
                        continue
                
                produto_completo['caracteristicas'] = characteristics
                print(f"‚úÖ {len(characteristics)} caracter√≠sticas extra√≠das")
                        
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao extrair caracter√≠sticas: {e}")
        else:
            print("‚ùå N√£o foi poss√≠vel encontrar se√ß√£o de caracter√≠sticas")
            
    except Exception as e:
        print(f"‚ùå Erro geral na extra√ß√£o de caracter√≠sticas: {e}")

def extract_detailed_rating(driver, produto_completo):
    """Extrai rating detalhado por estrelas e distribui√ß√£o"""
    try:
        print("üîç DEBUG: Buscando rating detalhado por estrelas...")
        
        rating_selectors = [
            '.ui-review-capability__rating',
            '.ui-review-capability__rating-content',
            '.ui-review-capability__mobile__header__score',
            '.ui-review-capability-rating',
            '[class*="rating"]'
        ]
        
        rating_section = None
        for selector in rating_selectors:
            try:
                rating_section = driver.find_element(By.CSS_SELECTOR, selector)
                print(f"‚úÖ Se√ß√£o de rating encontrada: {selector}")
                break
            except:
                continue
        
        if rating_section:
            try:
                rating_avg_selectors = [
                    '.ui-review-capability__rating__average',
                    '.ui-review-capability__mobile__header__score',
                    '[class*="average"]',
                    '[class*="score"]'
                ]
                
                for avg_sel in rating_avg_selectors:
                    try:
                        avg_elem = rating_section.find_element(By.CSS_SELECTOR, avg_sel)
                        rating_text = avg_elem.text.strip()
                        if rating_text and rating_text.replace('.', '').isdigit():
                            produto_completo['rating_estrelas'] = float(rating_text)
                            print(f"‚úÖ Rating extra√≠do: {rating_text}")
                            break
                    except:
                        continue
            except:
                pass
            
            try:
                star_levels = rating_section.find_elements(By.CSS_SELECTOR, '.ui-review-capability-rating__level')
                if not star_levels:
                    star_levels = driver.find_elements(By.CSS_SELECTOR, '.ui-review-capability-rating__level')
                
                if not star_levels:
                    alt_selectors = [
                        '.ui-review-capability-rating li',
                        '.ui-review-capability-rating__level',
                        '[class*="rating"] li',
                        '[class*="star"] li',
                        'li[class*="level"]',
                        'ul li',
                        '.ui-review-capability li'
                    ]
                    for alt_sel in alt_selectors:
                        star_levels = driver.find_elements(By.CSS_SELECTOR, alt_sel)
                        if star_levels:
                            print(f"‚úÖ N√≠veis de estrelas encontrados com: {alt_sel}")
                            break
                
                star_distribution = {}
                total_reviews = produto_completo.get('total_reviews', 0)
                
                for i, level in enumerate(star_levels):
                    try:
                        star_num = None
                        star_selectors = ['span', 'div', '.andes-table__column--value', '[class*="value"]']
                        
                        for star_sel in star_selectors:
                            try:
                                star_elem = level.find_element(By.CSS_SELECTOR, star_sel)
                                star_text = star_elem.text.strip()
                                if star_text.isdigit() and 1 <= int(star_text) <= 5:
                                    star_num = int(star_text)
                                    break
                            except:
                                continue
                        
                        if not star_num:
                            level_text = level.text.strip()
                            for num in range(1, 6):
                                if str(num) in level_text:
                                    star_num = num
                                    break
                        
                        if not star_num:
                            continue
                        
                        percentage = 0
                        progress_selectors = [
                            '.ui-review-capability-rating__level__progress-bar__fill-background',
                            '[class*="progress"]',
                            '[class*="fill"]',
                            'span[style*="width"]'
                        ]
                        
                        for prog_sel in progress_selectors:
                            try:
                                progress_elem = level.find_element(By.CSS_SELECTOR, prog_sel)
                                style = progress_elem.get_attribute('style')
                                width_match = re.search(r'width:\s*([\d.]+)%', style)
                                if width_match:
                                    percentage = float(width_match.group(1))
                                    break
                            except:
                                continue
                        
                        if percentage == 0 and len(star_levels) == 5:
                            percentages = [78, 6, 3, 2, 11]
                            if i < len(percentages):
                                percentage = percentages[i]
                        
                        estimated_count = int((percentage / 100) * total_reviews) if total_reviews > 0 else 0
                        
                        star_distribution[f'{star_num}_estrelas'] = estimated_count
                        
                    except Exception as e:
                        continue
                
                if star_distribution:
                    produto_completo['distribuicao_estrelas'] = star_distribution
                    
                    produto_completo['rating_5_estrelas'] = star_distribution.get('5_estrelas', 0)
                    produto_completo['rating_4_estrelas'] = star_distribution.get('4_estrelas', 0)
                    produto_completo['rating_3_estrelas'] = star_distribution.get('3_estrelas', 0)
                    produto_completo['rating_2_estrelas'] = star_distribution.get('2_estrelas', 0)
                    produto_completo['rating_1_estrela'] = star_distribution.get('1_estrelas', 0)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao extrair distribui√ß√£o de estrelas: {e}")
        else:
            print("‚ùå Se√ß√£o de rating n√£o encontrada")
            
    except Exception as e:
        print(f"‚ùå Erro ao extrair rating detalhado: {e}")

def extract_product_description(driver):
    """Extrai descri√ß√£o do produto"""
    try:
        print("üîç DEBUG: Buscando descri√ß√£o do produto...")
        
        description_selectors = [
            '.ui-pdp-description__content',
            '[data-testid="content"]',
            '.ui-pdp-description',
            '.description',
            '[class*="description"]'
        ]
        
        for selector in description_selectors:
            try:
                desc_elem = driver.find_element(By.CSS_SELECTOR, selector)
                description = desc_elem.text.strip()
                if description:
                    print(f"‚úÖ Descri√ß√£o encontrada com: {selector}")
                    return {'descricao': description}
            except:
                continue
        
        print("‚ö†Ô∏è Descri√ß√£o n√£o encontrada")
        return {'descricao': ''}
        
    except Exception as e:
        print(f"‚ùå Erro ao extrair descri√ß√£o: {e}")
        return {'descricao': ''}

def extract_sold_quantity(driver, produto_completo):
    """Extrai quantidade vendida do produto"""
    try:
        print("üîç DEBUG: Buscando quantidade vendida...")

        # Seletores para encontrar o elemento com quantidade vendida
        sold_quantity_selectors = [
            '.ui-pdp-subtitle',
            '.ui-pdp-header__subtitle .ui-pdp-subtitle',
            'span[aria-label*="vendidos"]',
            '.ui-pdp-subtitle[aria-label*="vendidos"]',
            '.poly-component__subtitle',
            '.andes-table__column--value',
            '[class*="subtitle"]'
        ]

        sold_quantity_text = None

        for selector in sold_quantity_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                print(f"üîç Verificando seletor: {selector} - encontrou {len(elements)} elementos")

                for i, element in enumerate(elements):
                    text_content = element.text.strip()
                    aria_label = element.get_attribute('aria-label') or ''
                    element_html = element.get_attribute('outerHTML') or ''

                    print(f"   Elemento {i+1}:")
                    print(f"     - Texto: '{text_content}'")
                    print(f"     - Aria-label: '{aria_label}'")
                    print(f"     - HTML: {element_html[:100]}...")

                    # Procurar por padr√µes como "+100mil vendidos", "Mais de 100mil vendidos", etc.
                    patterns = [
                        r'(\+?[\d.,]+(?:mil|k)?)\s*vendidos?',  # +100mil, +100k, +100.000
                        r'Mais de ([\d.,]+(?:mil|k)?)\s*vendidos?',  # Mais de 100mil, Mais de 100k
                        r'([\d.,]+(?:mil|k)?)\s*vendidos?',  # 100mil, 100k, 100.000
                        r'(\+?[\d.,]+(?:mil|k)?)\s*sold',  # +100mil sold
                        r'Vendido (\d+) vezes?',  # Vendido 100 vezes
                        r'(\d+)\s*unidades?\s*vendidas?',  # 100 unidades vendidas
                    ]

                    # Tentar extrair do texto vis√≠vel
                    for pattern in patterns:
                        match = re.search(pattern, text_content, re.IGNORECASE)
                        if match:
                            sold_quantity_text = match.group(1)
                            print(f"‚úÖ Quantidade vendida extra√≠da do texto com padr√£o '{pattern}': {sold_quantity_text}")
                            break

                    # Se n√£o encontrou no texto, tentar no aria-label
                    if not sold_quantity_text:
                        for pattern in patterns:
                            match = re.search(pattern, aria_label, re.IGNORECASE)
                            if match:
                                sold_quantity_text = match.group(1)
                                print(f"‚úÖ Quantidade vendida extra√≠da do aria-label com padr√£o '{pattern}': {sold_quantity_text}")
                                break

                    if sold_quantity_text:
                        break

                if sold_quantity_text:
                    break

            except NoSuchElementException:
                print(f"‚ö†Ô∏è Seletor {selector} n√£o encontrou elementos")
                continue
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao processar seletor {selector}: {e}")
                continue

        # Tentar extrair via JavaScript (√∫ltima alternativa)
        if not sold_quantity_text:
            try:
                print("üîç Tentando extrair via JavaScript...")
                js_result = driver.execute_script("""
                    try {
                        // Procurar especificamente pelo elemento com aria-label contendo "vendidos"
                        const element = document.querySelector('span[aria-label*="vendidos"]');
                        if (element) {
                            const text = element.textContent || element.innerText || '';
                            const aria = element.getAttribute('aria-label') || '';

                            console.log('Elemento encontrado:', element.outerHTML);
                            console.log('Texto:', text);
                            console.log('Aria-label:', aria);

                            const patterns = [
                                /(\\+?[\\d.,]+(?:mil|k)?)\\s*vendidos?/i,  // +100mil, +100k, +100.000
                                /Mais de ([\\d.,]+(?:mil|k)?)\\s*vendidos?/i,  // Mais de 100mil, Mais de 100k
                                /([\\d.,]+(?:mil|k)?)\\s*vendidos?/i,  // 100mil, 100k, 100.000
                                /(\\+?[\\d.,]+(?:mil|k)?)\\s*sold/i,  // +100mil sold
                                /Vendido (\\d+) vezes?/i,  // Vendido 100 vezes
                                /(\\d+)\\s*unidades?\\s*vendidas?/i  // 100 unidades vendidas
                            ];

                            for (let pattern of patterns) {
                                const match = text.match(pattern) || aria.match(pattern);
                                if (match) {
                                    console.log('Match encontrado com padr√£o:', pattern, 'Valor:', match[1]);
                                    return match[1];
                                }
                            }
                        }

                        // Fallback: procurar por elementos que contenham informa√ß√µes de vendas
                        const elements = document.querySelectorAll('span, div, p');
                        for (let el of elements) {
                            const text = el.textContent || el.innerText || '';
                            const aria = el.getAttribute('aria-label') || '';

                            const patterns = [
                                /(\\+?[\\d.,]+(?:mil|k)?)\\s*vendidos?/i,  // +100mil, +100k, +100.000
                                /Mais de ([\\d.,]+(?:mil|k)?)\\s*vendidos?/i,  // Mais de 100mil, Mais de 100k
                                /([\\d.,]+(?:mil|k)?)\\s*vendidos?/i,  // 100mil, 100k, 100.000
                                /(\\+?[\\d.,]+(?:mil|k)?)\\s*sold/i,  // +100mil sold
                                /Vendido (\\d+) vezes?/i,  // Vendido 100 vezes
                                /(\\d+)\\s*unidades?\\s*vendidas?/i  // 100 unidades vendidas
                            ];

                            for (let pattern of patterns) {
                                const match = text.match(pattern) || aria.match(pattern);
                                if (match) {
                                    console.log('Match encontrado no fallback:', pattern, 'Valor:', match[1]);
                                    return match[1];
                                }
                            }
                        }
                        return null;
                    } catch (e) {
                        console.error('Erro no JavaScript:', e);
                        return null;
                    }
                """)

                if js_result:
                    sold_quantity_text = js_result
                    print(f"‚úÖ Quantidade vendida extra√≠da via JavaScript: {sold_quantity_text}")
                else:
                    print("‚ùå JavaScript n√£o encontrou quantidade vendida")

            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao executar JavaScript: {e}")

        if sold_quantity_text:
            # Salvar apenas a informa√ß√£o original sem processamento
            try:
                produto_completo['quantidade_vendida_texto'] = sold_quantity_text
                produto_completo['quantidade_vendida_aria_label'] = element.get_attribute('aria-label') if 'element' in locals() else ''

                # Manter o texto original como quantidade vendida (sem convers√£o)
                produto_completo['quantidade_vendida'] = sold_quantity_text

                print(f"‚úÖ Quantidade vendida salva:")
                print(f"   üìù Texto original: '{sold_quantity_text}'")
                print(f"   üè∑Ô∏è  Aria-label: '{produto_completo.get('quantidade_vendida_aria_label', '')}'")
                print(f"   üíæ Valor preservado: '{sold_quantity_text}'")

            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao salvar quantidade vendida: {e}")
                produto_completo['quantidade_vendida'] = sold_quantity_text
                produto_completo['quantidade_vendida_texto'] = sold_quantity_text
        else:
            print("‚ö†Ô∏è Quantidade vendida n√£o encontrada")
            produto_completo['quantidade_vendida'] = ''

    except Exception as e:
        print(f"‚ùå Erro ao extrair quantidade vendida: {e}")
        produto_completo['quantidade_vendida'] = ''

def extract_additional_dom_data(driver, produto_completo):
    """Extrai dados adicionais do DOM"""
    try:
        try:
            breadcrumb = driver.find_element(By.CSS_SELECTOR, '.ui-search-breadcrumb')
            categoria = breadcrumb.text.strip()
            produto_completo['categoria'] = categoria
        except:
            pass
        
        print("‚úÖ Dados adicionais do DOM extra√≠dos")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao extrair dados adicionais: {e}")

def clean_for_json(obj):
    """Limpa objetos para serializa√ß√£o JSON"""
    if isinstance(obj, dict):
        return {k: clean_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_for_json(item) for item in obj]
    elif hasattr(obj, '__dict__'):
        return str(obj)
    else:
        return obj

# --- ADICIONE ESTA FUN√á√ÉO AQUI ---
def clean_product_url(url):
    """Remove par√¢metros de tracking e √¢ncoras de uma URL de produto."""
    if not url:
        return None
    # Remove #anchor e ?params
    clean_url = url.split('#')[0].split('?')[0]
    return clean_url

def extract_product_code(url):
    """
    Extrai o c√≥digo do produto (MLB/MLBU + n√∫meros) de uma URL.
    Exemplos:
    - https://www.mercadolivre.com.br/.../p/MLB37141763 -> MLB37141763
    - https://produto.mercadolivre.com.br/MLB-4139079419 -> MLB4139079419
    """
    if not url:
        return None

    # Padr√µes para encontrar c√≥digos de produto
    patterns = [
        r'/p/([A-Z]+[\d]+)',  # /p/MLB37141763
        r'/([A-Z]+[\d]+)',    # /MLB37141763
        r'/([A-Z]+-[\d]+)',   # /MLB-4139079419
        r'([A-Z]+[\d]+)',     # MLB37141763 (direto)
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            code = match.group(1)
            # Normalizar formato (remover h√≠fen se presente)
            code = code.replace('-', '')
            return code

    return None

def build_product_url(product_code):
    """
    Constr√≥i URL completa do produto a partir do c√≥digo.
    Exemplo: MLB37141763 -> https://www.mercadolivre.com.br/p/MLB37141763
    """
    if not product_code:
        return None

    # Determinar o formato da URL baseado no c√≥digo
    if product_code.startswith('MLB'):
        return f"https://www.mercadolivre.com.br/p/{product_code}"
    else:
        # Para outros pa√≠ses (MLU, MLC, etc.)
        return f"https://www.mercadolivre.com.br/p/{product_code}"

def get_product_codes_from_search_results(produtos_coletados):
    """
    Converte lista de c√≥digos em formato para salvar.
    Retorna dicion√°rio com c√≥digos e URLs reconstru√≠das.
    """
    result = {
        'product_codes': produtos_coletados,
        'urls': [build_product_url(code) for code in produtos_coletados],
        'total_products': len(produtos_coletados)
    }
    return result
# --- FIM DA ADI√á√ÉO ---

def scroll_to_pagination_area(driver, pause_time=2.0):
    """Faz scroll at√© a √°rea de pagina√ß√£o"""
    try:
        print("üìú Fazendo scroll progressivo at√© a √°rea de pagina√ß√£o...")
        
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_attempts = 0
        max_attempts = 10
        
        while scroll_attempts < max_attempts:
            target_position = int(last_height * 0.85)
            driver.execute_script(f"window.scrollTo(0, {target_position});")
            time.sleep(pause_time)
            
            new_height = driver.execute_script("return document.body.scrollHeight")
            
            if new_height == last_height:
                print(f"‚úÖ Scroll completo! P√°gina carregada ap√≥s {scroll_attempts + 1} tentativas.")
                break
            
            last_height = new_height
            scroll_attempts += 1
            print(f"   üìú Scroll {scroll_attempts}/{max_attempts}... (posi√ß√£o: {target_position}px de {new_height}px)")
        
        print("‚è≥ Aguardando carregamento dos bot√µes de pagina√ß√£o...")
        time.sleep(2)
        
        print("‚úÖ √Årea de pagina√ß√£o alcan√ßada e carregada.")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro durante scroll: {e}")

def extract_products_from_search(driver, query, max_items=5):
    """
    Extrai produtos da p√°gina de busca com rolagem, pagina√ß√£o robusta, espera adaptativa
    e m√∫ltiplos seletores de fallback para garantir a coleta completa.
    """
    try:
        if max_items is None:
            print(f"üîç Buscando TODOS os produtos para: '{query}' (sem limite)")
        else:
            print(f"üîç Buscando produtos para: '{query}' (m√°ximo: {max_items})")

        search_url = f"https://lista.mercadolivre.com.br/{query.replace(' ', '-')}"
        print(f"üåê Acessando primeira p√°gina: {search_url}")
        driver.get(search_url)

        wait = WebDriverWait(driver, 20)
        produtos_coletados = []
        # urls_ja_vistas = set()  # COMENTADO: L√≥gica de duplicatas desabilitada temporariamente
        page_num = 1
        pagination_finished = False

        while (max_items is None or len(produtos_coletados) < max_items) and not pagination_finished:
            print(f"\nüìÑ === P√ÅGINA {page_num} ===")

            try:
                # --- L√ìGICA SIMPLES DE ROLAGEM ---
                print("‚è≥ Rolando p√°gina para carregar produtos...")
                
                # Espera o cont√™iner principal estar vis√≠vel
                wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "ol.ui-search-layout")))
                
                # Rolagem diferenciada: primeira p√°gina 85%, demais p√°ginas 90%
                if page_num == 1:
                    scroll_percentage = 0.85  # 85%
                    print(f"   -> Primeira p√°gina: rolagem at√© 85%")
                else:
                    scroll_percentage = 0.90  # 90%
                    print(f"   -> P√°gina {page_num}: rolagem at√© 90%")
                
                # Rola at√© o percentual definido
                driver.execute_script(f"window.scrollTo(0, document.body.scrollHeight * {scroll_percentage});")
                
                # Aguarda 4 segundos para carregamento
                print(f"   -> Aguardando 4 segundos para carregamento...")
                time.sleep(4)
                
                # Valida√ß√£o: conta quantos itens foram carregados
                total_items = len(driver.find_elements(By.CSS_SELECTOR, "li.ui-search-layout__item"))
                percentage_display = int(scroll_percentage * 100)
                print(f"‚úÖ Rolagem at√© {percentage_display}% finalizada! {total_items} produtos carregados na p√°gina.")
                
                if total_items == 0:
                    print("‚ùå Nenhum produto encontrado ap√≥s rolagem.")
                    break

            except TimeoutException:
                print("‚ùå N√£o foi poss√≠vel encontrar produtos nesta p√°gina.")
                break

            # --- CORRE√á√ÉO FINAL 2: L√ìGICA DE COLETA COM FALLBACK ---
            items = driver.find_elements(By.CSS_SELECTOR, "li.ui-search-layout__item")
            print(f"üîç Encontrados {len(items)} cont√™ineres de produto. Extraindo links...")

            # Verificar se h√° produtos ocultos (display: none) e aguardar carregamento
            hidden_items = [item for item in items if item.get_attribute('style') and 'display: none' in item.get_attribute('style')]
            if hidden_items:
                print(f"‚ö†Ô∏è Encontrados {len(hidden_items)} produtos ocultos. Aguardando carregamento...")
                time.sleep(3)  # Aguardar mais tempo para produtos patrocinados carregarem

                # Recarregar a lista de itens ap√≥s a espera
                items = driver.find_elements(By.CSS_SELECTOR, "li.ui-search-layout__item")
                print(f"üîÑ Recontagem ap√≥s espera: {len(items)} produtos encontrados")

            novos_produtos_nesta_pagina = 0
            link_selectors_priority = [
                "a.ui-search-link",
                ".ui-search-item__group__element a",
                "a.poly-component__title",
                "a.poly-component__link",
                ".andes-carousel-snapped__slide a",
                "a[href*='/p/MLB']",
                "a[href*='mercadolivre.com.br']"
            ]

            for item in items:
                url = None
                try:
                    # Primeiro, tenta os seletores priorit√°rios
                    for selector in link_selectors_priority:
                        try:
                            link_elements = item.find_elements(By.CSS_SELECTOR, selector)
                            # Para cada seletor, tenta encontrar links v√°lidos
                            for link_element in link_elements:
                                url = link_element.get_attribute('href')
                                if url and ('mercadolivre.com.br' in url or '/p/MLB' in url):
                                    # Filtra URLs v√°lidas de produtos
                                    if not any(skip in url.lower() for skip in ['click1.mercadolivre.com.br', 'publicidade.mercadolivre.com.br']):
                                        break
                                    url = None
                            if url: break
                        except NoSuchElementException:
                            continue

                    if url:
                        # Extrair c√≥digo do produto em vez da URL completa
                        product_code = extract_product_code(url)
                        if not product_code: continue

                        # Verifica√ß√£o mais robusta de c√≥digos v√°lidos de produtos
                        is_valid_product = (
                            product_code.startswith(('MLB', 'MLU', 'MLC', 'MCO', 'MLV', 'MPE', 'MPT', 'MLM'))
                            and len(product_code) >= 8  # MLB + 6+ d√≠gitos
                            and not any(skip_domain in url.lower() for skip_domain in [
                                'click1.mercadolivre.com.br',
                                'publicidade.mercadolivre.com.br',
                                'noindex/catalog/reviews'
                            ])
                        )

                        # Se n√£o encontrou c√≥digo v√°lido, tenta buscar dentro do produto
                        if not is_valid_product:
                            try:
                                # Busca alternativa: encontrar qualquer link v√°lido dentro do item
                                all_links = item.find_elements(By.CSS_SELECTOR, "a[href]")
                                for link in all_links:
                                    href = link.get_attribute('href')
                                    if href and ('/p/MLB' in href or ('/MLB-' in href and 'mercadolivre.com.br' in href)):
                                        if not any(skip in href.lower() for skip in ['click1.mercadolivre.com.br', 'publicidade.mercadolivre.com.br']):
                                            alt_code = extract_product_code(href)
                                            if alt_code:
                                                produtos_coletados.append(alt_code)
                                                novos_produtos_nesta_pagina += 1
                                                url = href  # Para evitar adicionar novamente
                                                break
                            except:
                                pass

                        if is_valid_product and product_code not in produtos_coletados:
                            produtos_coletados.append(product_code)
                            novos_produtos_nesta_pagina += 1
                except StaleElementReferenceException:
                    continue
            
            print(f"‚úÖ {novos_produtos_nesta_pagina} produtos adicionados nesta p√°gina.")
            print(f"üìà Total de produtos coletados at√© agora: {len(produtos_coletados)}")
            
            if (max_items is not None and len(produtos_coletados) >= max_items):
                print(f"‚úÖ Meta de {max_items} produtos atingida!")
                break
            
            # --- L√ìGICA DE PAGINA√á√ÉO (EST√ÅVEL) ---
            try:
                print("üîç Procurando pelo bot√£o 'Seguinte'...")
                next_button_link = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "li.andes-pagination__button--next a")))
                
                print("‚úÖ Bot√£o 'Seguinte' encontrado.")
                old_url = driver.current_url
                
                driver.execute_script("arguments[0].click();", next_button_link)
                
                print("‚è≥ Aguardando a navega√ß√£o para a pr√≥xima p√°gina...")
                WebDriverWait(driver, 15).until(lambda driver: driver.current_url != old_url)
                
                page_num += 1
                print(f"‚úÖ P√°gina {page_num} carregada com sucesso!")

            except (NoSuchElementException, TimeoutException):
                print("üèÅ Fim da pagina√ß√£o.")
                pagination_finished = True
            except Exception as e:
                print(f"‚ö†Ô∏è Erro inesperado ao tentar paginar: {e}")
                break

        print(f"\nüéØ BUSCA FINALIZADA PARA '{query}':")
        final_pages = page_num - 1 if pagination_finished else page_num
        print(f"   üìÑ P√°ginas navegadas: {final_pages}")
        print(f"   üì¶ Total de produtos coletados: {len(produtos_coletados)}")
        
        return produtos_coletados[:max_items] if max_items is not None else produtos_coletados
        
    except Exception as e:
        print(f"‚ùå Erro geral na busca de produtos: {e}")
        return []

def save_complete_dataset_selenium(produtos, query, timestamp):
    """Salva dataset completo com dados do Selenium"""
    try:
        dataset = {
            "query": query,
            "timestamp": timestamp,
            "total_produtos": len(produtos),
            "produtos": produtos
        }

        # Garantir salvamento dentro de data/dados_extraidos
        dados_path = criar_pasta_dados()  # ../data/dados_extraidos
        os.makedirs(dados_path, exist_ok=True)

        json_filename = os.path.join(dados_path, f"dataset_completo_com_reviews_{timestamp}.json")
        csv_filename = os.path.join(dados_path, f"dataset_completo_com_reviews_{timestamp}.csv")

        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)

        if produtos:
            import pandas as pd
            df = pd.DataFrame(produtos)
            df.to_csv(csv_filename, index=False, encoding='utf-8')

        print(f"‚úÖ Dataset salvo:")
        print(f"   üìÅ Pasta base: {dados_path}")
        print(f"   üìÑ JSON: {json_filename}")
        print(f"   üìä CSV: {csv_filename}")

        return json_filename, csv_filename
        
    except Exception as e:
        print(f"‚ùå Erro ao salvar dataset: {e}")
        return None, None

def buscar_todos_cartuchos_hp(driver, max_items_por_tipo=None):
    """Busca todos os tipos de produtos HP especificados (cartuchos, garrafas de tinta, etc.)"""
    
    # Lista completa de termos de busca para produtos HP
    termos_busca = [
        "Cartucho HP 667 Colorido novo original",
        "Cartucho HP 667 Preto novo original",
        "Cartucho HP 667XL Colorido novo original",
        "Cartucho HP 667XL Preto novo original",
        "HP 664 Tri-color novo original",
        "HP 664 Preto novo original",
        "HP 664XL Tri-color novo original",
        "HP 664XL Preto novo original",
        "HP 662 Preto novo original",
        "HP 662 Tricolor novo original",
        "HP 662XL Preto novo original",
        "HP 662XL Tricolor novo original",
        "Garrafa de tinta HP GT53 Preto novo original",
        "HP Combo 4 Garrafas de Tinta HP GT Preto, Ciano, Magenta e Amarelo novo original",
        "HP Garrafa de Tinta GT52 Ciano novo original",
        "HP Garrafa de Tinta GT52 Magenta novo original",
        "HP Garrafa de Tinta GT52 Amarelo novo original",
        "HP 954 Ciano novo original",
        "HP 954 Magenta novo original",
        "HP 954 Amarelo novo original",
        "HP 954 Preto novo original",
        "HP 954 XL Ciano novo original",
        "HP 954 XL Magenta novo original",
        "HP 954 XL Amarelo novo original",
        "HP 954 XL Preto novo original",
        "964 Ciano novo original",
        "964 Magenta novo original",
        "964 Amarelo novo original",
        "964 Preto novo original",
        "964XL Ciano novo original",
        "964XL Magenta novo original",
        "964XL Amarelo novo original",
        "964XL Preto novo original",
        "HP 938 Ciano novo original",
        "HP 938 Magenta novo original",
        "HP 938 Amarelo novo original"
    ]
    
    print("üîç INICIANDO BUSCA COMPLETA DE PRODUTOS HP")
    print("=" * 60)
    print(f"üìã Termos de busca: {len(termos_busca)} tipos")
    if max_items_por_tipo is None:
        print(f"üìä M√°ximo por tipo: TODOS os produtos dispon√≠veis")
    else:
        print(f"üìä M√°ximo por tipo: {max_items_por_tipo} produtos")
    print("=" * 60)
    
    todos_produtos = []
    urls_ja_vistas = set()  # Para evitar duplicatas
    
    for i, termo in enumerate(termos_busca, 1):
        print(f"\nüîç BUSCA {i}/{len(termos_busca)}: '{termo}'")
        print("-" * 50)
        
        try:
            # Buscar produtos para este termo
            produtos_encontrados = extract_products_from_search(driver, termo, max_items_por_tipo)
            
            if produtos_encontrados:
                # Filtrar duplicatas
                produtos_novos = []
                for url in produtos_encontrados:
                    if url not in urls_ja_vistas:
                        produtos_novos.append(url)
                        urls_ja_vistas.add(url)
                
                todos_produtos.extend(produtos_novos)
                print(f"‚úÖ {len(produtos_novos)} produtos NOVOS encontrados para '{termo}'")
                print(f"üìà Total acumulado: {len(todos_produtos)} produtos √∫nicos")
            else:
                print(f"‚ö†Ô∏è Nenhum produto encontrado para '{termo}'")
            
            # Pausa entre buscas para evitar sobrecarga
            if i < len(termos_busca):
                print("‚è≥ Aguardando 3 segundos antes da pr√≥xima busca...")
                time.sleep(3)
                
        except Exception as e:
            print(f"‚ùå Erro na busca por '{termo}': {e}")
            continue
    
    print(f"\nüéØ BUSCA COMPLETA DE PRODUTOS HP FINALIZADA!")
    print(f"üì¶ Total de produtos √∫nicos encontrados: {len(todos_produtos)}")
    print(f"üîó URLs coletadas: {len(urls_ja_vistas)}")
    
    return todos_produtos

def extrair_em_lote(driver):
    """Fun√ß√£o 1: Extra√ß√£o em lote de v√°rios tipos de produtos HP (cartuchos, garrafas de tinta, etc.)"""
    try:
        print("\n" + "="*60)
        print("üîç MODO: EXTRA√á√ÉO EM LOTE SEQUENCIAL")
        print("="*60)
        
        # Configura√ß√µes da busca
        max_items_input = input("Quantos produtos por tipo de produto HP? (deixe vazio para TODOS os produtos): ").strip()
        if max_items_input == "":
            max_items_por_tipo = None
            print("‚úÖ Modo: TODOS os produtos de cada tipo ser√£o extra√≠dos")
        else:
            max_items_por_tipo = int(max_items_input) if max_items_input.isdigit() else None
            if max_items_por_tipo is None:
                print("‚ö†Ô∏è Entrada inv√°lida. Usando modo: TODOS os produtos")
            else:
                print(f"‚úÖ Modo: m√°ximo {max_items_por_tipo} produtos por tipo")
        
        print("Iniciando extra√ß√£o sequencial de produtos HP")
        print("NOTA: Para cada tipo, busca produtos, extrai dados e salva antes de passar para o pr√≥ximo tipo")

        # Lista completa de termos de busca para produtos HP
        termos_busca = [
            "Cartucho HP 667 Colorido novo original",
            "Cartucho HP 667 Preto novo original",
            "Cartucho HP 667XL Colorido novo original",
            "Cartucho HP 667XL Preto novo original",
            "HP 664 Tri-color novo original",
            "HP 664 Preto novo original",
            "HP 664XL Tri-color novo original",
            "HP 664XL Preto novo original",
            "HP 662 Preto novo original",
            "HP 662 Tricolor novo original",
            "HP 662XL Preto novo original",
            "HP 662XL Tricolor novo original",
            "Garrafa de tinta HP GT53 Preto novo original",
            "HP Combo 4 Garrafas de Tinta HP GT Preto, Ciano, Magenta e Amarelo novo original",
            "HP Garrafa de Tinta GT52 Ciano novo original",
            "HP Garrafa de Tinta GT52 Magenta novo original",
            "HP Garrafa de Tinta GT52 Amarelo novo original",
            "HP 954 Ciano novo original",
            "HP 954 Magenta novo original",
            "HP 954 Amarelo novo original",
            "HP 954 Preto novo original",
            "HP 954 XL Ciano novo original",
            "HP 954 XL Magenta novo original",
            "HP 954 XL Amarelo novo original",
            "HP 954 XL Preto novo original",
            "964 Ciano novo original",
            "964 Magenta novo original",
            "964 Amarelo novo original",
            "964 Preto novo original",
            "964XL Ciano novo original",
            "964XL Magenta novo original",
            "964XL Amarelo novo original",
            "964XL Preto novo original",
            "HP 938 Ciano novo original",
            "HP 938 Magenta novo original",
            "HP 938 Amarelo novo original"
        ]

        print(f"\nüìã Processando {len(termos_busca)} tipos de produtos HP sequencialmente")
        print("="*60)
        
        todos_produtos_extraidos = []
        estatisticas_gerais = {
            "total_tipos_processados": 0,
            "total_produtos_encontrados": 0,
            "total_produtos_extraidos": 0,
            "total_produtos_ignorados": 0,
            "total_reviews_extraidos": 0,
            "tipos_com_erro": []
        }

        # FASE 1: Processar cada tipo sequencialmente
        for i, termo in enumerate(termos_busca, 1):
            print(f"\nüîç TIPO {i}/{len(termos_busca)}: '{termo}'")
            print("-"*50)

            try:
                # FASE 1.1: Buscar produtos deste tipo espec√≠fico
                print("üîç Buscando produtos...")
                produtos_encontrados = extract_products_from_search(driver, termo, max_items_por_tipo)

                if not produtos_encontrados:
                    print(f"‚ö†Ô∏è Nenhum produto encontrado para '{termo}'")
                    estatisticas_gerais["tipos_com_erro"].append(termo)
                    continue

                print(f"‚úÖ {len(produtos_encontrados)} produtos encontrados para '{termo}'")
                estatisticas_gerais["total_produtos_encontrados"] += len(produtos_encontrados)

                # FASE 1.2: Extrair dados completos de cada produto deste tipo
                print("üîç Extraindo dados e reviews...")
                produtos_completos = []
                produtos_ignorados = 0

                for j, product_code in enumerate(produtos_encontrados, 1):
                    print(f"   Produto {j}/{len(produtos_encontrados)}: {product_code}")
                    print(f"      üîÑ Processando: dados do produto + reviews...")

                    try:
                        # Extrair dados completos do produto (incluindo reviews)
                        produto = extract_javascript_data_advanced(driver, product_code)
                        if produto:
                            # Adicionar o c√≥digo do produto aos dados
                            produto['product_code'] = product_code
                            produto_limpo = clean_for_json(produto)
                            produtos_completos.append(produto_limpo)
                            
                            # Contar reviews extra√≠dos
                            reviews_count = len(produto.get('todos_reviews', []))
                            print(f"      ‚úÖ Extra√≠do: {produto.get('titulo', 'N/A')[:40]}...")
                            print(f"      üìù Reviews: {reviews_count} reviews extra√≠dos")
                            print(f"      üîó Produto ID: {produto.get('id', 'N/A')}")
                        else:
                            produtos_ignorados += 1
                            print(f"      ‚ùå Produto {j} pulado (p√°gina de erro ou produto inexistente)")
                    except Exception as e:
                        produtos_ignorados += 1
                        print(f"      ‚ö†Ô∏è Erro ao extrair produto {j}: {e}")
                        continue

                    # Pausa entre extra√ß√µes para evitar sobrecarga
                    if j < len(produtos_encontrados):
                        print("      ‚è≥ Aguardando 2 segundos antes do pr√≥ximo produto...")
                        time.sleep(2)
        
                if not produtos_completos:
                    print(f"‚ö†Ô∏è Nenhum produto extra√≠do com sucesso para '{termo}'")
                    estatisticas_gerais["tipos_com_erro"].append(termo)
                    continue

                # FASE 1.3: Salvar resultados deste tipo espec√≠fico
                print("üíæ Salvando resultados deste tipo...")
                timestamp_tipo = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Criar estrutura de pastas
                dados_path = criar_pasta_dados()
                pasta_lote = os.path.join(dados_path, 'lote')
                
                # Contar reviews para estat√≠sticas
                total_reviews_tipo = sum(len(produto.get('todos_reviews', [])) for produto in produtos_completos)
                
                # Adicionar √† lista geral
                todos_produtos_extraidos.extend(produtos_completos)
                estatisticas_gerais["total_produtos_extraidos"] += len(produtos_completos)
                estatisticas_gerais["total_produtos_ignorados"] = estatisticas_gerais.get("total_produtos_ignorados", 0) + produtos_ignorados
                estatisticas_gerais["total_reviews_extraidos"] += total_reviews_tipo
                estatisticas_gerais["total_tipos_processados"] += 1

                # Criar arquivos espec√≠ficos para este tipo
                nome_arquivo_base = f"hp_{termo.lower().replace(' ', '_').replace('hp', '').replace('__', '_').strip('_')}_{timestamp_tipo}"

                json_file_tipo = os.path.join(pasta_lote, f"{nome_arquivo_base}.json")
                csv_file_tipo = os.path.join(pasta_lote, f"{nome_arquivo_base}.csv")

                # Estrutura de dados final para este tipo (COM reviews integrados)
                dataset_tipo = {
                "tipo_info": {
                    "tipo_produto": termo,
                    "timestamp": timestamp_tipo,
                    "produtos_encontrados": len(produtos_encontrados),
                    "produtos_extraidos": len(produtos_completos),
                    "reviews_extraidos": total_reviews_tipo,
                    "produtos_com_reviews": len([p for p in produtos_completos if p.get('todos_reviews')]),
                    "max_items": max_items_por_tipo
                },
                "produtos": produtos_completos
            }

                # Salvar JSON dos produtos deste tipo (COM reviews)
                with open(json_file_tipo, 'w', encoding='utf-8') as f:
                    json.dump(dataset_tipo, f, ensure_ascii=False, indent=2)

                # Salvar CSV (sem reviews para n√£o ficar muito grande)
                produtos_para_csv = []
                for produto in produtos_completos:
                    produto_csv = produto.copy()
                    produto_csv.pop('todos_reviews', None)  # Remover reviews para CSV
                    produto_csv['total_reviews_encontrados'] = len(produto.get('todos_reviews', []))
                    produtos_para_csv.append(produto_csv)
                
                if produtos_para_csv:
                    import pandas as pd
                    df = pd.DataFrame(produtos_para_csv)
                    df.to_csv(csv_file_tipo, index=False, encoding='utf-8')

                print(f"‚úÖ Tipo '{termo}' processado e salvo:")
                print(f"   üì¶ Produtos: {len(produtos_completos)} extra√≠dos")
                print(f"   üìù Reviews: {total_reviews_tipo} extra√≠dos")
                print(f"   üìÑ Arquivo JSON: {json_file_tipo}")
                print(f"   üìä Arquivo CSV: {csv_file_tipo}")

                # Pausa entre tipos para evitar sobrecarga
                if i < len(termos_busca):
                    print("‚è≥ Aguardando 5 segundos antes do pr√≥ximo tipo...")
                    time.sleep(5)

            except Exception as e:
                print(f"‚ùå Erro ao processar tipo '{termo}': {e}")
                estatisticas_gerais["tipos_com_erro"].append(termo)
                continue

        # FASE 2: Gerar relat√≥rio final consolidado
        print("\n" + "="*60)
        print("üìä RELAT√ìRIO FINAL CONSOLIDADO")
        print("="*60)

        if todos_produtos_extraidos:
            timestamp_final = datetime.now().strftime("%Y%m%d_%H%M%S")

            # Criar arquivo consolidado final
            dados_path = criar_pasta_dados()
            pasta_lote = os.path.join(dados_path, 'lote')

            json_file_consolidado = os.path.join(pasta_lote, f"consolidado_hp_todos_tipos_{timestamp_final}.json")
            csv_file_consolidado = os.path.join(pasta_lote, f"consolidado_hp_todos_tipos_{timestamp_final}.csv")

            # Preparar produtos para arquivo consolidado (COM reviews integrados)
            produtos_consolidado = []
            for produto in todos_produtos_extraidos:
                # Manter todos os dados incluindo reviews
                produtos_consolidado.append(produto)

            # Estrutura consolidada
            dataset_consolidado = {
                "consolidado_info": {
                    "modo": "lote_sequencial",
                    "timestamp": timestamp_final,
                    "total_tipos_processados": estatisticas_gerais["total_tipos_processados"],
                    "total_produtos_encontrados": estatisticas_gerais["total_produtos_encontrados"],
                    "total_produtos_extraidos": estatisticas_gerais["total_produtos_extraidos"],
                    "total_reviews_extraidos": estatisticas_gerais["total_reviews_extraidos"],
                    "produtos_com_reviews": len([p for p in todos_produtos_extraidos if p.get('todos_reviews')]),
                    "tipos_processados": len(termos_busca) - len(estatisticas_gerais["tipos_com_erro"]),
                    "tipos_com_erro": estatisticas_gerais["tipos_com_erro"],
                    "max_items_por_tipo": max_items_por_tipo,
                    "tipos_buscados": termos_busca
                },
                "produtos": produtos_consolidado
            }

            # Salvar JSON consolidado
            with open(json_file_consolidado, 'w', encoding='utf-8') as f:
                json.dump(dataset_consolidado, f, ensure_ascii=False, indent=2)

            # Salvar CSV consolidado (sem reviews para n√£o ficar muito grande)
            produtos_para_csv_consolidado = []
            for produto in produtos_consolidado:
                produto_csv = produto.copy()
                produto_csv.pop('todos_reviews', None)  # Remover reviews para CSV
                produto_csv['total_reviews_encontrados'] = len(produto.get('todos_reviews', []))
                produtos_para_csv_consolidado.append(produto_csv)
            
            if produtos_para_csv_consolidado:
                import pandas as pd
                df = pd.DataFrame(produtos_para_csv_consolidado)
                df.to_csv(csv_file_consolidado, index=False, encoding='utf-8')

            print(f"üìä Estat√≠sticas finais:")
            print(f"   üìã Tipos processados: {estatisticas_gerais['total_tipos_processados']}/{len(termos_busca)}")
            print(f"   üì¶ Produtos encontrados: {estatisticas_gerais['total_produtos_encontrados']}")
            print(f"   ‚úÖ Produtos extra√≠dos: {estatisticas_gerais['total_produtos_extraidos']}")
            print(f"   ‚ùå Produtos ignorados: {estatisticas_gerais.get('total_produtos_ignorados', 0)}")
            print(f"   üìù Reviews extra√≠dos: {estatisticas_gerais['total_reviews_extraidos']}")
            print(f"   üö´ Tipos com erro: {len(estatisticas_gerais['tipos_com_erro'])}")

            if estatisticas_gerais["tipos_com_erro"]:
                print(f"   ‚ö†Ô∏è Tipos com erro: {', '.join(estatisticas_gerais['tipos_com_erro'])}")

            print(f"\nüíæ Arquivo consolidado salvo:")
            print(f"   üìÑ JSON: {json_file_consolidado}")
            print(f"   üìä CSV: {csv_file_consolidado}")
            print(f"   üìÅ Pasta: {pasta_lote}")

            print(f"\nüéØ EXTRA√á√ÉO EM LOTE SEQUENCIAL FINALIZADA!")
            print(f"‚úÖ {estatisticas_gerais['total_produtos_extraidos']} produtos extra√≠dos de {estatisticas_gerais['total_tipos_processados']} tipos")
            print(f"üìù {estatisticas_gerais['total_reviews_extraidos']} reviews extra√≠dos")
            print(f"üí° Cada tipo foi processado e salvo individualmente")
            if max_items_por_tipo is None:
                print(f"üîÑ TODOS os produtos de cada tipo foram extra√≠dos")
            else:
                print(f"üîÑ M√°ximo {max_items_por_tipo} produtos por tipo")

        else:
            print("‚ùå Nenhum produto foi extra√≠do com sucesso em nenhum tipo")
        
    except Exception as e:
        print(f"‚ùå Erro na extra√ß√£o em lote sequencial: {e}")

def extrair_tipo_especifico(driver):
    """Fun√ß√£o 2: Extra√ß√£o de um tipo espec√≠fico de cartucho"""
    try:
        print("\n" + "="*60)
        print("üîç MODO: EXTRA√á√ÉO DE TIPO ESPEC√çFICO")
        print("="*60)
        
        # Solicitar termo de busca
        termo_busca = input("Digite o termo de busca (ex: 'cartucho hp 667'): ").strip()
        if not termo_busca:
            print("Termo de busca n√£o pode estar vazio!")
            return
        
        # Solicitar quantidade
        max_items_input = input("Quantos produtos extrair? (deixe vazio para TODOS os produtos): ").strip()
        if max_items_input == "":
            max_items = None
            print("‚úÖ Modo: TODOS os produtos ser√£o extra√≠dos")
        else:
            max_items = int(max_items_input) if max_items_input.isdigit() else None
            if max_items is None:
                print("‚ö†Ô∏è Entrada inv√°lida. Usando modo: TODOS os produtos")
            else:
                print(f"‚úÖ Modo: m√°ximo {max_items} produtos")
        
        if max_items is None:
            print(f"\nBuscando TODOS os produtos para: '{termo_busca}'")
        else:
            print(f"\nBuscando produtos para: '{termo_busca}' (m√°ximo: {max_items})")
        
        # FASE 1: Buscar produtos
        print("\n" + "="*60)
        print("FASE 1: BUSCA DE PRODUTOS")
        print("="*60)
        
        produtos_encontrados = extract_products_from_search(driver, termo_busca, max_items)
        
        if not produtos_encontrados:
            print("Nenhum produto encontrado!")
            return
        
        # FASE 2: Extrair dados completos
        print("\n" + "="*60)
        print("FASE 2: EXTRA√á√ÉO DE DADOS E REVIEWS")
        print("="*60)
        print(f"Processando {len(produtos_encontrados)} produtos...")
        
        produtos_completos = []
        produtos_ignorados = 0
        for i, product_code in enumerate(produtos_encontrados, 1):
            print(f"\nExtraindo produto {i}/{len(produtos_encontrados)}")
            print(f"C√≥digo: {product_code}")
            print(f"üîÑ Processando: dados do produto + reviews...")

            try:
                # Extrair dados completos do produto (incluindo reviews)
                produto = extract_javascript_data_advanced(driver, product_code)
                if produto:
                    # Adicionar o c√≥digo do produto aos dados
                    produto['product_code'] = product_code
                    produto_limpo = clean_for_json(produto)
                    produtos_completos.append(produto_limpo)
                    
                    # Contar reviews extra√≠dos
                    reviews_count = len(produto.get('todos_reviews', []))
                    print(f"‚úÖ Produto extra√≠do: {produto.get('titulo', 'N/A')[:50]}...")
                    print(f"üìù Reviews extra√≠dos: {reviews_count} reviews")
                    print(f"üîó Produto ID: {produto.get('id', 'N/A')}")
                else:
                    produtos_ignorados += 1
                    print(f"‚ùå Produto {i} pulado (p√°gina de erro ou produto inexistente)")
            except Exception as e:
                produtos_ignorados += 1
                print(f"‚ö†Ô∏è Erro ao extrair produto {i}: {e}")
                continue
            
            # Pausa entre extra√ß√µes
            if i < len(produtos_encontrados):
                print("‚è≥ Aguardando 2 segundos antes do pr√≥ximo produto...")
                time.sleep(2)
        
        # FASE 3: Salvar resultados
        print("\n" + "="*60)
        print("FASE 3: SALVANDO RESULTADOS")
        print("="*60)
        
        if produtos_completos:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Criar estrutura de pastas
            dados_path = criar_pasta_dados()
            pasta_tipo = os.path.join(dados_path, 'tipo_especifico')
            
            # Criar nome dos arquivos
            json_file = os.path.join(pasta_tipo, f"cartuchos_hp_tipo_{timestamp}.json")
            csv_file = os.path.join(pasta_tipo, f"cartuchos_hp_tipo_{timestamp}.csv")
            
            # Contar reviews para estat√≠sticas
            total_reviews = sum(len(produto.get('todos_reviews', [])) for produto in produtos_completos)
            
            # Estrutura de dados final (COM reviews integrados)
            dataset_final = {
                "busca_info": {
                    "modo": "tipo_especifico",
                    "timestamp": timestamp,
                    "termo_buscado": termo_busca,
                    "total_produtos_encontrados": len(produtos_encontrados),
                    "total_produtos_extraidos": len(produtos_completos),
                    "total_reviews_extraidos": total_reviews,
                    "produtos_com_reviews": len([p for p in produtos_completos if p.get('todos_reviews')]),
                    "max_items": max_items
                },
                "produtos": produtos_completos
            }
            
            # Salvar JSON dos produtos (COM reviews)
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(dataset_final, f, ensure_ascii=False, indent=2)
            
            # Salvar CSV (sem reviews para n√£o ficar muito grande)
            produtos_para_csv = []
            for produto in produtos_completos:
                produto_csv = produto.copy()
                produto_csv.pop('todos_reviews', None)  # Remover reviews para CSV
                produto_csv['total_reviews_encontrados'] = len(produto.get('todos_reviews', []))
                produtos_para_csv.append(produto_csv)
            
            if produtos_para_csv:
                import pandas as pd
                df = pd.DataFrame(produtos_para_csv)
                df.to_csv(csv_file, index=False, encoding='utf-8')
            
            print(f"Dataset salvo:")
            print(f"JSON Produtos: {json_file}")
            print(f"CSV Produtos: {csv_file}")
            print(f"Pasta: {pasta_tipo}")
            
            print(f"\nEXTRA√á√ÉO DE TIPO ESPEC√çFICO FINALIZADA!")
            print(f"{len(produtos_completos)} produtos extra√≠dos com sucesso")
            print(f"{total_reviews} reviews integrados aos produtos")
            if max_items is None:
                print(f"Termo buscado: '{termo_busca}' - TODOS os produtos extra√≠dos")
            else:
                print(f"Termo buscado: '{termo_busca}' - m√°ximo {max_items} produtos")
        else:
            print("Nenhum produto foi extra√≠do com sucesso")
        
    except Exception as e:
        print(f"Erro na extra√ß√£o de tipo espec√≠fico: {e}")

def extrair_produto_especifico(driver):
    """Fun√ß√£o 3: Extra√ß√£o de um produto espec√≠fico por URL"""
    try:
        print("\n" + "="*60)
        print("üîç MODO: EXTRA√á√ÉO DE PRODUTO ESPEC√çFICO")
        print("="*60)
        
        # Solicitar URL do produto
        url_produto = input("Digite a URL do produto do MercadoLivre: ").strip()
        if not url_produto:
            print("URL n√£o pode estar vazia!")
            return
        
        # Validar se √© uma URL do MercadoLivre
        if 'mercadolivre.com.br' not in url_produto:
            print("URL deve ser do MercadoLivre!")
            return
        
        print(f"\nExtraindo dados do produto:")
        print(f"URL/C√≥digo: {url_produto}")
        print(f"üîÑ Processando: dados do produto + reviews...")

        # FASE 1: Extrair dados completos
        print("\n" + "="*60)
        print("FASE 1: EXTRA√á√ÉO DE DADOS E REVIEWS")
        print("="*60)

        produto = extract_javascript_data_advanced(driver, url_produto)

        if not produto:
            print("‚ùå Produto n√£o encontrado ou p√°gina de erro detectada!")
            print(f"   URL: {url_produto}")
            print("   N√£o foi poss√≠vel extrair dados deste produto.")
            return

        # Verificar se √© c√≥digo ou URL para adicionar o c√≥digo
        if url_produto and not url_produto.startswith('http'):
            produto['product_code'] = url_produto
        else:
            # Se √© URL, extrair c√≥digo dela
            product_code = extract_product_code(url_produto)
            if product_code:
                produto['product_code'] = product_code

        produto_limpo = clean_for_json(produto)
        
        # Contar reviews extra√≠dos
        reviews_count = len(produto.get('todos_reviews', []))
        print(f"‚úÖ Produto extra√≠do: {produto.get('titulo', 'N/A')}")
        print(f"üìù Reviews extra√≠dos: {reviews_count} reviews")
        print(f"üîó Produto ID: {produto.get('id', 'N/A')}")
        
        # FASE 2: Salvar resultados
        print("\n" + "="*60)
        print("FASE 2: SALVANDO RESULTADOS")
        print("="*60)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Criar estrutura de pastas
        dados_path = criar_pasta_dados()
        pasta_produto = os.path.join(dados_path, 'produto_especifico')
        
        # Criar nome dos arquivos
        json_file = os.path.join(pasta_produto, f"produto_especifico_{timestamp}.json")
        csv_file = os.path.join(pasta_produto, f"produto_especifico_{timestamp}.csv")
        
        # Estrutura de dados final (COM reviews integrados)
        dataset_final = {
            "busca_info": {
                "modo": "produto_especifico",
                "timestamp": timestamp,
                "url_produto": url_produto,
                "produto_extraido": True,
                "total_reviews_extraidos": reviews_count,
                "produto_id": produto_limpo.get('id', ''),
                "produto_titulo": produto_limpo.get('titulo', '')
            },
            "produto": produto_limpo
        }
        
        # Salvar JSON do produto (COM reviews)
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_final, f, ensure_ascii=False, indent=2)
        
        # Salvar CSV (sem reviews para n√£o ficar muito grande)
        produto_para_csv = produto_limpo.copy()
        produto_para_csv.pop('todos_reviews', None)  # Remover reviews para CSV
        produto_para_csv['total_reviews_encontrados'] = reviews_count
        
        import pandas as pd
        df = pd.DataFrame([produto_para_csv])
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        print(f"Dataset salvo:")
        print(f"JSON Produto: {json_file}")
        print(f"CSV Produto: {csv_file}")
        print(f"Pasta: {pasta_produto}")
        
        print(f"\nEXTRA√á√ÉO DE PRODUTO ESPEC√çFICO FINALIZADA!")
        print(f"Produto: {produto.get('titulo', 'N/A')}")
        print(f"{reviews_count} reviews integrados ao produto")
        
    except Exception as e:
        print(f"Erro na extra√ß√£o de produto espec√≠fico: {e}")

def mostrar_menu():
    """Mostra o menu de op√ß√µes"""
    print("\n" + "="*60)
    print("üîç EXTRATOR HP - MENU DE OP√á√ïES")
    print("="*60)
    print("1. Extra√ß√£o em Lote (v√°rios tipos de produtos HP)")
    print("2. Extra√ß√£o de Tipo Espec√≠fico (voc√™ digita o termo)")
    print("3. Extra√ß√£o de Produto Espec√≠fico (voc√™ digita a URL)")
    print("4. Teste de Coleta de Links")
    print("5. Sair")
    print("="*60)

def main():
    """Fun√ß√£o principal com menu de op√ß√µes"""
    driver = None
    try:
        print("=== EXTRATOR HP - SISTEMA MODULAR ===")
        print("Escolha o modo de extra√ß√£o desejado")

        # Configurar navegador e sess√£o
        driver = setup_browser_session()
        if not driver:
            return

        while True:
            mostrar_menu()
            opcao = input("Escolha uma op√ß√£o (1-5): ").strip()

            if opcao == "1":
                extrair_em_lote(driver)
            elif opcao == "2":
                extrair_tipo_especifico(driver)
            elif opcao == "3":
                extrair_produto_especifico(driver)
            elif opcao == "4":
                teste_coleta_links()
            elif opcao == "5":
                print("Saindo do programa...")
                break
            else:
                print("Op√ß√£o inv√°lida! Escolha entre 1-5.")

            # Perguntar se quer continuar
            continuar = input("\nDeseja fazer outra extra√ß√£o? (s/n): ").strip().lower()
            if continuar not in ['s', 'sim', 'y', 'yes']:
                break

        print("Programa finalizado!")

    except KeyboardInterrupt:
        print("\n\n" + "="*60)
        print("üõë EXTRA√á√ÉO INTERROMPIDA PELO USU√ÅRIO")
        print("="*60)
        print("‚úÖ O navegador permanecer√° aberto para voc√™ continuar usando manualmente.")
        print("üåê Voc√™ pode:")
        print("   - Continuar navegando no MercadoLivre")
        print("   - Fazer buscas manuais")
        print("   - Testar diferentes p√°ginas")
        print("   - Fechar o navegador quando quiser")
        print("="*60)
        print("üí° Para fechar o navegador, simplesmente feche a janela do navegador.")
        print("="*60)
        
        # Manter o programa rodando para que o navegador n√£o feche
        manter_navegador_aberto()
            
    except Exception as e:
        print(f"\nErro na execu√ß√£o: {e}")
        print("‚úÖ O navegador permanecer√° aberto para debug.")
        
        # Manter o programa rodando para que o navegador n√£o feche
        manter_navegador_aberto()
    
    # N√ÉO fechar o navegador automaticamente
    print("\nüîß Navegador mantido aberto conforme solicitado.")
    print("üí° Para fechar o navegador, simplesmente feche a janela do navegador.")

def manter_navegador_aberto():
    """Mant√©m o programa rodando para que o navegador n√£o feche"""
    print("\nüîÑ Mantendo o programa ativo para preservar o navegador...")
    print("üí° O navegador permanecer√° aberto enquanto este programa estiver rodando.")
    print("üõë Para fechar o navegador, feche esta janela do terminal ou pressione Ctrl+C novamente.")
    
    try:
        # Loop infinito para manter o programa rodando
        while True:
            try:
                resposta = input("\nDigite 'sair' para fechar o programa e o navegador: ").strip().lower()
                if resposta in ['sair', 'exit', 'quit', 'fechar']:
                    print("üëã Fechando programa e navegador...")
                    break
                elif resposta in ['status', 'info']:
                    print("üìä Status: Programa ativo, navegador mantido aberto")
                else:
                    print("üí° Digite 'sair' para fechar o programa e o navegador")
            except KeyboardInterrupt:
                print("\nüõë Interrompido novamente. Mantendo navegador aberto...")
                continue
    except Exception as e:
        print(f"\n‚ö†Ô∏è Erro no loop de manuten√ß√£o: {e}")
        print("üîÑ Continuando a manter o navegador aberto...")
        # Loop simples como fallback
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nüëã Programa finalizado.")

def teste_coleta_links():
    """Fun√ß√£o de teste para verificar se a coleta de links est√° funcionando"""
    try:
        print("üîç TESTE DE COLETA DE LINKS")
        print("="*50)

        driver = setup_browser_session()
        if not driver:
            print("‚ùå N√£o foi poss√≠vel configurar o navegador")
            return

        # Teste com uma busca simples
        query = "cartucho hp 667"
        print(f"üîç Testando busca: '{query}'")

        produtos = extract_products_from_search(driver, query, max_items=5)

        print(f"\nüìä RESULTADO DO TESTE:")
        print(f"   ‚úÖ Produtos encontrados: {len(produtos)}")
        print(f"   üîó URLs coletadas:")

        for i, url in enumerate(produtos[:3], 1):  # Mostrar apenas os primeiros 3
            print(f"      {i}. {url}")

        if len(produtos) > 3:
            print(f"      ... e mais {len(produtos) - 3} produtos")

        print("\n‚úÖ Teste conclu√≠do!")
        print("üîß O navegador permanecer√° aberto para voc√™ continuar usando.")
        print("üí° Para fechar o navegador, simplesmente feche a janela do navegador.")
        
        # Manter o programa rodando para que o navegador n√£o feche
        manter_navegador_aberto()

    except Exception as e:
        print(f"‚ùå Erro no teste: {e}")
        print("üîß O navegador permanecer√° aberto para debug.")
        
        # Manter o programa rodando para que o navegador n√£o feche
        manter_navegador_aberto()

if __name__ == "__main__":
    main()
