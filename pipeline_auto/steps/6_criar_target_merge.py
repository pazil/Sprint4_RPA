#!/usr/bin/env python3
"""
SCRIPT 6: CRIAR TARGET E MERGE FINAL
=====================================
Cria a variÃ¡vel target is_fraud_suspect_v2 e faz o merge de todas as features.

INPUT:
- data/script_3_features_basicas/dataset_com_features_basicas_*.csv
- data/script_4_nlp/reviews_com_nlp_*.csv
- data/script_5_imagens/hashes_imagens.csv

OUTPUT:
- data/script_6_grafo/dataset_final_para_modelo.csv (PRONTO PARA ML)
"""

import pandas as pd
import numpy as np
import os
import json

# --- CONFIGURAÃ‡ÃƒO ---
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent))
from _config import *

# Usar os arquivos mais recentes de cada script
PATH_FEATURES_BASICAS = max(SCRIPT_3_DIR.glob("*.csv"), key=lambda x: x.stat().st_mtime)
PATH_REVIEWS_NLP = max(SCRIPT_4_DIR.glob("*.csv"), key=lambda x: x.stat().st_mtime)
PATH_HASHES_IMAGENS = SCRIPT_5_DIR / "hashes_imagens.csv"
PATH_OUTPUT = SCRIPT_6_DIR / "dataset_final_para_modelo.csv"

# Criar diretÃ³rio de saÃ­da se nÃ£o existir
SCRIPT_6_DIR.mkdir(parents=True, exist_ok=True)

def criar_is_fraud_suspect_v2(df):
    """
    Cria variÃ¡vel target is_fraud_suspect_v2 (versÃ£o melhorada)
    
    CRITÃ‰RIOS DE SUSPEITA (11 critÃ©rios):
    ======================================
    
    ğŸ”´ CRITÃ‰RIOS FORTES (2 pontos cada):
    1. PreÃ§o MUITO abaixo do mercado (< -30%)
    2. Imagem reutilizada em MUITOS produtos (>10x)
    3. Vendedor com reputaÃ§Ã£o MUITO RUIM (1_red)
    4. Alta % de reviews negativas (>30%)
    
    ğŸŸ  CRITÃ‰RIOS MÃ‰DIOS (1 ponto cada):
    5. PreÃ§o moderadamente abaixo (-15% a -30%)
    6. Imagem reutilizada moderadamente (3-10x)
    7. Vendedor com reputaÃ§Ã£o RUIM (2_orange)
    8. InconsistÃªncia XL no tÃ­tulo
    9. Vendedor NOVO com poucos produtos (<50 transaÃ§Ãµes)
    
    ğŸŸ¡ CRITÃ‰RIOS FRACOS (0.5 ponto cada):
    10. PreÃ§o ligeiramente abaixo (-5% a -15%)
    11. Reviews negativas moderadas (15-30%)
    
    â­ PENALIDADE ESPECIAL:
    - Loja Oficial com mÃºltiplos critÃ©rios suspeitos (+1 ponto)
      (Para detectar o caso da loja oficial fraudulenta da HP)
    
    THRESHOLD: score >= 3.0 â†’ SUSPEITO
    """
    
    print("\n" + "="*80)
    print("ğŸ¯ CRIANDO VARIÃVEL TARGET: is_fraud_suspect_v2")
    print("="*80)
    
    # Inicializar score e flags individuais
    df['score_de_suspeita'] = 0.0
    
    # Flags individuais para rastrear cada critÃ©rio
    df['flag_preco_muito_baixo'] = 0  # < -30%
    df['flag_preco_medio_baixo'] = 0  # -15% a -30%
    df['flag_preco_ligeiramente_baixo'] = 0  # -5% a -15%
    df['flag_imagem_muito_reutilizada'] = 0  # >10x
    df['flag_imagem_reutilizada'] = 0  # 3-10x
    df['flag_reputacao_muito_ruim'] = 0  # <= 1
    df['flag_reputacao_ruim'] = 0  # <= 2
    df['flag_reviews_muito_negativas'] = 0  # >30%
    df['flag_reviews_negativas'] = 0  # 15-30%
    df['flag_inconsistencia_xl'] = 0  # InconsistÃªncia XL
    df['flag_vendedor_novo'] = 0  # <50 transaÃ§Ãµes
    df['flag_loja_oficial_suspeita'] = 0  # Loja oficial com mÃºltiplos critÃ©rios
    df['flag_fraude_instantanea'] = 0  # PreÃ§o < -30% (regra especial)
    
    # --- 1. ANÃLISE DE PREÃ‡O ---
    print("\nğŸ“Š CRITÃ‰RIO 1-3: ANÃLISE DE PREÃ‡O")
    
    # PreÃ§o MUITO abaixo (-30% ou mais)
    mask_preco_muito_baixo = df['diferenca_preco_perc'] < -0.30
    df.loc[mask_preco_muito_baixo, 'score_de_suspeita'] += 2.0
    df.loc[mask_preco_muito_baixo, 'flag_preco_muito_baixo'] = 1
    print(f"   ğŸ”´ PreÃ§o < -30%: {mask_preco_muito_baixo.sum()} produtos (+2.0 pontos)")
    
    # PreÃ§o moderadamente abaixo (-15% a -30%)
    mask_preco_medio = (df['diferenca_preco_perc'] >= -0.30) & (df['diferenca_preco_perc'] < -0.15)
    df.loc[mask_preco_medio, 'score_de_suspeita'] += 1.0
    df.loc[mask_preco_medio, 'flag_preco_medio_baixo'] = 1
    print(f"   ğŸŸ  PreÃ§o -15% a -30%: {mask_preco_medio.sum()} produtos (+1.0 ponto)")
    
    # PreÃ§o ligeiramente abaixo (-5% a -15%)
    mask_preco_leve = (df['diferenca_preco_perc'] >= -0.15) & (df['diferenca_preco_perc'] < -0.05)
    df.loc[mask_preco_leve, 'score_de_suspeita'] += 0.5
    df.loc[mask_preco_leve, 'flag_preco_ligeiramente_baixo'] = 1
    print(f"   ğŸŸ¡ PreÃ§o -5% a -15%: {mask_preco_leve.sum()} produtos (+0.5 ponto)")
    
    # --- 2. ANÃLISE DE IMAGEM (se disponÃ­vel) ---
    print("\nğŸ–¼ï¸ CRITÃ‰RIO 4-5: ANÃLISE DE REUSO DE IMAGEM")
    
    if 'contagem_reuso_imagem' in df.columns:
        # Reuso MUITO alto (>10x)
        mask_reuso_alto = df['contagem_reuso_imagem'] > 10
        df.loc[mask_reuso_alto, 'score_de_suspeita'] += 2.0
        print(f"   ğŸ”´ Reuso > 10x: {mask_reuso_alto.sum()} produtos (+2.0 pontos)")
        
        # Reuso moderado (3-10x)
        mask_reuso_medio = (df['contagem_reuso_imagem'] >= 3) & (df['contagem_reuso_imagem'] <= 10)
        df.loc[mask_reuso_medio, 'score_de_suspeita'] += 1.0
        print(f"   ğŸŸ  Reuso 3-10x: {mask_reuso_medio.sum()} produtos (+1.0 ponto)")
    else:
        print("   âš ï¸ Coluna 'contagem_reuso_imagem' nÃ£o encontrada. Pulando...")
    
    # --- 3. ANÃLISE DE REPUTAÃ‡ÃƒO ---
    print("\nâ­ CRITÃ‰RIO 6-7: REPUTAÃ‡ÃƒO DO VENDEDOR")
    
    # ReputaÃ§Ã£o MUITO RUIM (1_red)
    mask_rep_ruim = df['vendedor_reputacao_num'] == 1
    df.loc[mask_rep_ruim, 'score_de_suspeita'] += 2.0
    print(f"   ğŸ”´ ReputaÃ§Ã£o 1_red: {mask_rep_ruim.sum()} produtos (+2.0 pontos)")
    
    # ReputaÃ§Ã£o RUIM (2_orange)
    mask_rep_regular = df['vendedor_reputacao_num'] == 2
    df.loc[mask_rep_regular, 'score_de_suspeita'] += 1.0
    print(f"   ğŸŸ  ReputaÃ§Ã£o 2_orange: {mask_rep_regular.sum()} produtos (+1.0 ponto)")
    
    # --- 4. ANÃLISE DE REVIEWS ---
    print("\nğŸ’¬ CRITÃ‰RIO 8-9: REVIEWS NEGATIVAS")
    
    # Reviews negativas ALTAS (>30%)
    mask_reviews_alta = df['perc_reviews_negativas'] > 0.30
    df.loc[mask_reviews_alta, 'score_de_suspeita'] += 2.0
    print(f"   ğŸ”´ Reviews negativas > 30%: {mask_reviews_alta.sum()} produtos (+2.0 pontos)")
    
    # Reviews negativas moderadas (15-30%)
    mask_reviews_media = (df['perc_reviews_negativas'] >= 0.15) & (df['perc_reviews_negativas'] <= 0.30)
    df.loc[mask_reviews_media, 'score_de_suspeita'] += 0.5
    print(f"   ğŸŸ¡ Reviews negativas 15-30%: {mask_reviews_media.sum()} produtos (+0.5 ponto)")
    
    # --- 5. INCONSISTÃŠNCIA XL ---
    print("\nğŸ”¤ CRITÃ‰RIO 10: INCONSISTÃŠNCIA XL")
    
    mask_xl = df['flag_inconsistencia_xl'] == 1
    df.loc[mask_xl, 'score_de_suspeita'] += 1.0
    print(f"   ğŸŸ  InconsistÃªncia XL: {mask_xl.sum()} produtos (+1.0 ponto)")
    
    # --- 6. VENDEDOR NOVO ---
    print("\nğŸ†• CRITÃ‰RIO 11: VENDEDOR NOVO")
    
    mask_novo = df['vendedor_total_transacoes'] < 50
    df.loc[mask_novo, 'score_de_suspeita'] += 1.0
    print(f"   ğŸŸ  Vendedor novo (<50 transaÃ§Ãµes): {mask_novo.sum()} produtos (+1.0 ponto)")
    
    # --- 7. PENALIDADE ESPECIAL: LOJA OFICIAL SUSPEITA ---
    print("\nâ­ PENALIDADE ESPECIAL: LOJA OFICIAL COM MÃšLTIPLOS CRITÃ‰RIOS")
    
    # Loja oficial com score >= 2.0 (jÃ¡ tem mÃºltiplos critÃ©rios suspeitos)
    mask_loja_oficial_suspeita = (df['e_loja_oficial'] == 1) & (df['score_de_suspeita'] >= 2.0)
    df.loc[mask_loja_oficial_suspeita, 'score_de_suspeita'] += 1.0
    print(f"   ğŸ”´ Loja oficial com mÃºltiplos critÃ©rios: {mask_loja_oficial_suspeita.sum()} produtos (+1.0 ponto)")
    print("   ğŸ’¡ Detecta casos como a loja oficial fraudulenta mencionada pela HP")
    
    # =============================================================================
    # REGRA DE FRAUDE INSTANTÃ‚NEA (MANTENDO OUTROS CRITÃ‰RIOS)
    # =============================================================================
    print("\nğŸš¨ APLICANDO REGRA DE FRAUDE INSTANTÃ‚NEA...")
    
    # A mÃ¡scara mask_preco_muito_baixo jÃ¡ foi definida na seÃ§Ã£o de anÃ¡lise de preÃ§o
    SCORE_INSTANTANEO = 10.0
    
    # CORREÃ‡ÃƒO: Somar em vez de sobrescrever para manter outros critÃ©rios
    # Primeiro, remover os 2 pontos jÃ¡ adicionados pelo critÃ©rio de preÃ§o
    df.loc[mask_preco_muito_baixo, 'score_de_suspeita'] -= 2.0
    # Depois, adicionar o score instantÃ¢neo
    df.loc[mask_preco_muito_baixo, 'score_de_suspeita'] += SCORE_INSTANTANEO
    # Marcar a flag de fraude instantÃ¢nea
    df.loc[mask_preco_muito_baixo, 'flag_fraude_instantanea'] = 1
    
    print(f"   âœ… {mask_preco_muito_baixo.sum()} produtos com preÃ§o < -30% tiveram seu score ajustado para {SCORE_INSTANTANEO}")
    print("   ğŸ’¡ Outros critÃ©rios (imagem, reputaÃ§Ã£o, etc.) foram mantidos no score final")
    # =============================================================================
    
    # --- 8. CRIAR TARGET BINÃRIO ---
    print("\n" + "="*80)
    print("ğŸ¯ DEFININDO THRESHOLD E CRIANDO TARGET")
    print("="*80)
    
    THRESHOLD = 3.0
    df['is_fraud_suspect_v2'] = (df['score_de_suspeita'] >= THRESHOLD).astype(int)
    
    print(f"\nğŸ“Š THRESHOLD: {THRESHOLD} pontos")
    print(f"   âœ… Produtos NÃƒO SUSPEITOS (score < {THRESHOLD}): {(df['is_fraud_suspect_v2'] == 0).sum()}")
    print(f"   âš ï¸ Produtos SUSPEITOS (score >= {THRESHOLD}): {(df['is_fraud_suspect_v2'] == 1).sum()}")
    print(f"   ğŸ“ˆ Taxa de suspeitos: {(df['is_fraud_suspect_v2'] == 1).sum() / len(df) * 100:.1f}%")
    
    # --- 9. ANÃLISE DE DISTRIBUIÃ‡ÃƒO DE SCORES ---
    print("\nğŸ“Š DISTRIBUIÃ‡ÃƒO DE SCORES:")
    print("-"*80)
    
    bins = [0, 1, 2, 3, 4, 5, 100]
    labels = ['0-1', '1-2', '2-3', '3-4', '4-5', '5+']
    df['score_faixa'] = pd.cut(df['score_de_suspeita'], bins=bins, labels=labels, include_lowest=True)
    
    distribuicao = df.groupby('score_faixa', observed=True).agg({
        'id_anuncio': 'count',
        'is_fraud_suspect_v2': 'sum'
    }).rename(columns={'id_anuncio': 'total_produtos', 'is_fraud_suspect_v2': 'num_suspeitos'})
    
    for faixa, row in distribuicao.iterrows():
        simbolo = "âœ…" if faixa in ['0-1', '1-2', '2-3'] else "âš ï¸"
        print(f"   {simbolo} Score {faixa}: {row['total_produtos']:>3} produtos ({row['num_suspeitos']:>2} suspeitos)")
    
    df.drop(columns=['score_faixa'], inplace=True)
    
    print("\nâœ… Target 'is_fraud_suspect_v2' criado com sucesso!")
    
    return df

def merge_all_features():
    """Faz merge de todas as features"""
    
    print("\n" + "="*80)
    print("ğŸ”— MERGE DE TODAS AS FEATURES")
    print("="*80)
    
    # 1. Carregar Features BÃ¡sicas
    print("\nğŸ“‚ 1. Carregando Features BÃ¡sicas...")
    df_base = pd.read_csv(PATH_FEATURES_BASICAS)
    print(f"   âœ… {len(df_base)} produtos, {len(df_base.columns)} colunas")
    
    # 2. Carregar Reviews NLP
    print("\nğŸ“‚ 2. Carregando Reviews NLP...")
    try:
        df_nlp = pd.read_csv(PATH_REVIEWS_NLP)
        print(f"   âœ… {len(df_nlp)} produtos com reviews, {len(df_nlp.columns)} colunas NLP")
        
        # Merge
        df_merged = pd.merge(df_base, df_nlp, on='id_anuncio', how='left')
        print(f"   âœ… Merge realizado: {len(df_merged)} produtos")
        
        # Preencher NaN para produtos sem reviews
        nlp_cols = [col for col in df_nlp.columns if col != 'id_anuncio']
        for col in nlp_cols:
            if col in df_merged.columns:
                if col.startswith('review_embedding_'):
                    df_merged[col] = df_merged[col].fillna(0.0)
                elif col == 'sentimento_medio_reviews':
                    df_merged[col] = df_merged[col].fillna(0.0)
                else:
                    df_merged[col] = df_merged[col].fillna(0)
        
        print(f"   âœ… NaN preenchidos para produtos sem reviews")
    except FileNotFoundError:
        print("   âš ï¸ Arquivo reviews_com_nlp.csv nÃ£o encontrado. Pulando NLP...")
        df_merged = df_base.copy()
    
    # 3. Carregar Hashes de Imagem
    print("\nğŸ“‚ 3. Carregando Hashes de Imagem...")
    
    # Tentar carregar hashes_imagens_COMPLETO.csv primeiro (mÃºltiplas imagens)
    hash_file_used = None
    if False:  # PATH_HASHES_COMPLETO nÃ£o existe mais
        print("   ğŸ” Detectado: hashes_imagens_COMPLETO.csv (mÃºltiplas imagens)")
        df_hashes = pd.read_csv(PATH_HASHES_COMPLETO)
        hash_file_used = 'COMPLETO'
        
        # Agregar: pegar a contagem MÃXIMA de reuso entre todas as imagens do produto
        print("   ğŸ“Š Agregando mÃºltiplas imagens por produto (MAX reuso)...")
        df_hashes_agg = df_hashes.groupby('id_anuncio').agg({
            'contagem_reuso_imagem': 'max',  # MÃ¡ximo reuso entre as imagens
            'phash': 'count'  # NÃºmero de imagens
        }).reset_index()
        df_hashes_agg.rename(columns={
            'contagem_reuso_imagem': 'contagem_reuso_imagem',
            'phash': 'num_imagens_produto'
        }, inplace=True)
        
        print(f"   âœ… {len(df_hashes_agg)} produtos com imagens")
        print(f"   ğŸ“Š MÃ©dia de imagens por produto: {df_hashes['id_anuncio'].value_counts().mean():.1f}")
        
    elif os.path.exists(PATH_HASHES_IMAGENS):
        print("   ğŸ” Detectado: hashes_imagens.csv (imagem principal)")
        df_hashes_agg = pd.read_csv(PATH_HASHES_IMAGENS)
        hash_file_used = 'SIMPLES'
        df_hashes_agg['num_imagens_produto'] = 1  # Apenas 1 imagem
        print(f"   âœ… {len(df_hashes_agg)} produtos com hash")
    else:
        print("   âš ï¸ Nenhum arquivo de hash encontrado. Criando placeholder...")
        df_hashes_agg = pd.DataFrame({
            'id_anuncio': df_merged['id_anuncio'],
            'contagem_reuso_imagem': 1,
            'num_imagens_produto': 0
        })
        hash_file_used = 'PLACEHOLDER'
    
    # Merge hashes
    df_final = pd.merge(df_merged, df_hashes_agg[['id_anuncio', 'contagem_reuso_imagem', 'num_imagens_produto']], 
                        on='id_anuncio', how='left')
    df_final['contagem_reuso_imagem'] = df_final['contagem_reuso_imagem'].fillna(1)
    df_final['num_imagens_produto'] = df_final['num_imagens_produto'].fillna(0)
    
    print(f"   âœ… Merge realizado: {len(df_final)} produtos")
    
    print("\n" + "="*80)
    print("ğŸ“Š RESUMO DO DATASET MERGED")
    print("="*80)
    print(f"   Total de produtos: {len(df_final)}")
    print(f"   Total de features: {len(df_final.columns)}")
    print(f"   Arquivo de hash usado: {hash_file_used}")
    
    return df_final

def main():
    print("="*80)
    print("ğŸ¯ SCRIPT 6: CRIAR TARGET E MERGE FINAL")
    print("="*80)
    
    # 1. Merge de todas as features
    df = merge_all_features()
    
    # 2. Criar target
    df = criar_is_fraud_suspect_v2(df)
    
    # 3. Salvar dataset final
    print("\n" + "="*80)
    print("ğŸ’¾ SALVANDO DATASET FINAL")
    print("="*80)
    
    df.to_csv(PATH_OUTPUT, index=False)
    print(f"âœ… Salvo: {os.path.abspath(PATH_OUTPUT)}")
    print(f"ğŸ“Š Shape: ({len(df)}, {len(df.columns)})")
    
    # 4. Resumo final
    print("\n" + "="*80)
    print("ğŸ“ˆ RESUMO FINAL DO DATASET")
    print("="*80)
    
    print(f"\nğŸ“¦ TOTAL: {len(df)} produtos")
    print(f"ğŸ“Š FEATURES: {len(df.columns)} colunas")
    print(f"\nğŸ¯ TARGET:")
    print(f"   âœ… NÃƒO SUSPEITOS: {(df['is_fraud_suspect_v2'] == 0).sum()} ({(df['is_fraud_suspect_v2'] == 0).sum() / len(df) * 100:.1f}%)")
    print(f"   âš ï¸ SUSPEITOS: {(df['is_fraud_suspect_v2'] == 1).sum()} ({(df['is_fraud_suspect_v2'] == 1).sum() / len(df) * 100:.1f}%)")
    
    print(f"\nğŸ“Š SCORE DE SUSPEITA:")
    print(f"   MÃ­nimo: {df['score_de_suspeita'].min():.1f}")
    print(f"   MÃ¡ximo: {df['score_de_suspeita'].max():.1f}")
    print(f"   MÃ©dia: {df['score_de_suspeita'].mean():.1f}")
    print(f"   Mediana: {df['score_de_suspeita'].median():.1f}")
    
    # Lista de features por categoria
    print(f"\nğŸ“‹ CATEGORIAS DE FEATURES:")
    
    feature_categories = {
        'ğŸ”´ IDENTIFICADORES': [col for col in df.columns if col in ['id_anuncio', 'titulo', 'link_anuncio', 'seller_id', 'vendedor_nome']],
        'ğŸŸ  PREÃ‡O': [col for col in df.columns if 'preco' in col.lower() or 'diferenca' in col.lower()],
        'ğŸŸ¡ VENDEDOR': [col for col in df.columns if 'vendedor' in col.lower() and col not in ['vendedor_id', 'vendedor_nome']],
        'ğŸŸ¢ REVIEWS': [col for col in df.columns if 'review' in col.lower() or 'rating' in col.lower()],
        'ğŸ”µ PRODUTO': [col for col in df.columns if col in ['tipo_cartucho', 'unidades_por_anuncio', 'cores_detalhadas', 'flag_inconsistencia_xl']],
        'ğŸŸ£ NLP': [col for col in df.columns if 'sentimento' in col.lower() or 'contagem_' in col.lower() or 'embedding' in col.lower()],
        'ğŸŸ¤ IMAGEM': [col for col in df.columns if 'imagem' in col.lower() or 'phash' in col.lower()],
        'âš« TARGET': [col for col in df.columns if 'fraud' in col.lower() or 'suspeita' in col.lower()]
    }
    
    for categoria, features in feature_categories.items():
        if features:
            print(f"   {categoria}: {len(features)} features")
    
    print("\n" + "="*80)
    print("âœ… SCRIPT 4 CONCLUÃDO COM SUCESSO!")
    print("="*80)
    print(f"\nğŸ“ PrÃ³ximo passo: Treinar o modelo com {PATH_OUTPUT}")

if __name__ == "__main__":
    main()


