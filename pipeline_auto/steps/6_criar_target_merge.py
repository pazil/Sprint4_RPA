#!/usr/bin/env python3
"""
SCRIPT 6: CRIAR TARGET E MERGE FINAL
=====================================
Cria a vari√°vel target is_fraud_suspect_v2 e faz o merge de todas as features.

INPUT:
- data/script_3_features_basicas/dataset_com_features_basicas_*.csv
- data/script_4_nlp/reviews_com_nlp_*.csv
- data/script_5_imagens/hashes_imagens.csv

OUTPUT:
- data/script_6_grafo/dataset_final_para_modelo.csv (PRONTO PARA ML)
"""

import pandas as pd
import numpy as np
import os
import json

# --- CONFIGURA√á√ÉO ---
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent))
from _config import *

# Usar os arquivos mais recentes de cada script
PATH_FEATURES_BASICAS = max(SCRIPT_3_DIR.glob("*.csv"), key=lambda x: x.stat().st_mtime)
PATH_REVIEWS_NLP = max(SCRIPT_4_DIR.glob("*.csv"), key=lambda x: x.stat().st_mtime)
PATH_HASHES_IMAGENS = SCRIPT_5_DIR / "hashes_imagens.csv"
PATH_OUTPUT = SCRIPT_6_DIR / "dataset_final_para_modelo.csv"

# Criar diret√≥rio de sa√≠da se n√£o existir
SCRIPT_6_DIR.mkdir(parents=True, exist_ok=True)

def criar_is_fraud_suspect_v2(df):
    """
    Cria vari√°vel target is_fraud_suspect_v2 (vers√£o melhorada)
    
    CRIT√âRIOS DE SUSPEITA (11 crit√©rios):
    ======================================
    
    üî¥ CRIT√âRIOS FORTES (2 pontos cada):
    1. Pre√ßo MUITO abaixo do mercado (< -30%)
    2. Imagem reutilizada em MUITOS produtos (>10x)
    3. Vendedor com reputa√ß√£o MUITO RUIM (1_red)
    4. Alta % de reviews negativas (>30%)
    
    üü† CRIT√âRIOS M√âDIOS (1 ponto cada):
    5. Pre√ßo moderadamente abaixo (-15% a -30%)
    6. Imagem reutilizada moderadamente (3-10x)
    7. Vendedor com reputa√ß√£o RUIM (2_orange)
    8. Inconsist√™ncia XL no t√≠tulo
    9. Vendedor NOVO com poucos produtos (<50 transa√ß√µes)
    
    üü° CRIT√âRIOS FRACOS (0.5 ponto cada):
    10. Pre√ßo ligeiramente abaixo (-5% a -15%)
    11. Reviews negativas moderadas (15-30%)
    
    ‚≠ê PENALIDADE ESPECIAL:
    - Loja Oficial com m√∫ltiplos crit√©rios suspeitos (+1 ponto)
      (Para detectar o caso da loja oficial fraudulenta da HP)
    
    THRESHOLD: score >= 3.0 ‚Üí SUSPEITO
    """
    
    print("\n" + "="*80)
    print("üéØ CRIANDO VARI√ÅVEL TARGET: is_fraud_suspect_v2")
    print("="*80)
    
    # Inicializar score e flags individuais
    df['score_de_suspeita'] = 0.0
    
    # Flags individuais para rastrear cada crit√©rio
    df['flag_preco_muito_baixo'] = 0  # < -30%
    df['flag_preco_medio_baixo'] = 0  # -15% a -30%
    df['flag_preco_ligeiramente_baixo'] = 0  # -5% a -15%
    df['flag_imagem_muito_reutilizada'] = 0  # >10x
    df['flag_imagem_reutilizada'] = 0  # 3-10x
    df['flag_reputacao_muito_ruim'] = 0  # <= 1
    df['flag_reputacao_ruim'] = 0  # <= 2
    df['flag_reviews_muito_negativas'] = 0  # >30%
    df['flag_reviews_negativas'] = 0  # 15-30%
    df['flag_inconsistencia_xl'] = 0  # Inconsist√™ncia XL
    df['flag_vendedor_novo'] = 0  # <50 transa√ß√µes
    df['flag_loja_oficial_suspeita'] = 0  # Loja oficial com m√∫ltiplos crit√©rios
    df['flag_fraude_instantanea'] = 0  # Pre√ßo < -30% (regra especial)
    
    # --- 1. AN√ÅLISE DE PRE√áO ---
    print("\nüìä CRIT√âRIO 1-3: AN√ÅLISE DE PRE√áO")
    
    # Pre√ßo MUITO abaixo (-30% ou mais)
    mask_preco_muito_baixo = df['diferenca_preco_perc'] < -0.30
    df.loc[mask_preco_muito_baixo, 'score_de_suspeita'] += 2.0
    df.loc[mask_preco_muito_baixo, 'flag_preco_muito_baixo'] = 1
    print(f"   üî¥ Pre√ßo < -30%: {mask_preco_muito_baixo.sum()} produtos (+2.0 pontos)")
    
    # Pre√ßo moderadamente abaixo (-15% a -30%)
    mask_preco_medio = (df['diferenca_preco_perc'] >= -0.30) & (df['diferenca_preco_perc'] < -0.15)
    df.loc[mask_preco_medio, 'score_de_suspeita'] += 1.0
    df.loc[mask_preco_medio, 'flag_preco_medio_baixo'] = 1
    print(f"   üü† Pre√ßo -15% a -30%: {mask_preco_medio.sum()} produtos (+1.0 ponto)")
    
    # Pre√ßo ligeiramente abaixo (-5% a -15%)
    mask_preco_leve = (df['diferenca_preco_perc'] >= -0.15) & (df['diferenca_preco_perc'] < -0.05)
    df.loc[mask_preco_leve, 'score_de_suspeita'] += 0.5
    df.loc[mask_preco_leve, 'flag_preco_ligeiramente_baixo'] = 1
    print(f"   üü° Pre√ßo -5% a -15%: {mask_preco_leve.sum()} produtos (+0.5 ponto)")
    
    # --- 2. AN√ÅLISE DE IMAGEM (se dispon√≠vel) ---
    print("\nüñºÔ∏è CRIT√âRIO 4-5: AN√ÅLISE DE REUSO DE IMAGEM")
    
    if 'contagem_reuso_imagem' in df.columns:
        # Reuso MUITO alto (>10x)
        mask_reuso_alto = df['contagem_reuso_imagem'] > 10
        df.loc[mask_reuso_alto, 'score_de_suspeita'] += 2.0
        print(f"   üî¥ Reuso > 10x: {mask_reuso_alto.sum()} produtos (+2.0 pontos)")
        
        # Reuso moderado (3-10x)
        mask_reuso_medio = (df['contagem_reuso_imagem'] >= 3) & (df['contagem_reuso_imagem'] <= 10)
        df.loc[mask_reuso_medio, 'score_de_suspeita'] += 1.0
        print(f"   üü† Reuso 3-10x: {mask_reuso_medio.sum()} produtos (+1.0 ponto)")
    else:
        print("   ‚ö†Ô∏è Coluna 'contagem_reuso_imagem' n√£o encontrada. Pulando...")
    
    # --- 3. AN√ÅLISE DE REPUTA√á√ÉO ---
    print("\n‚≠ê CRIT√âRIO 6-7: REPUTA√á√ÉO DO VENDEDOR")
    
    # Reputa√ß√£o MUITO RUIM (1_red)
    mask_rep_ruim = df['vendedor_reputacao_num'] == 1
    df.loc[mask_rep_ruim, 'score_de_suspeita'] += 2.0
    print(f"   üî¥ Reputa√ß√£o 1_red: {mask_rep_ruim.sum()} produtos (+2.0 pontos)")
    
    # Reputa√ß√£o RUIM (2_orange)
    mask_rep_regular = df['vendedor_reputacao_num'] == 2
    df.loc[mask_rep_regular, 'score_de_suspeita'] += 1.0
    print(f"   üü† Reputa√ß√£o 2_orange: {mask_rep_regular.sum()} produtos (+1.0 ponto)")
    
    # --- 4. AN√ÅLISE DE REVIEWS ---
    print("\nüí¨ CRIT√âRIO 8-9: REVIEWS NEGATIVAS")
    
    # Reviews negativas ALTAS (>30%)
    mask_reviews_alta = df['perc_reviews_negativas'] > 0.30
    df.loc[mask_reviews_alta, 'score_de_suspeita'] += 2.0
    print(f"   üî¥ Reviews negativas > 30%: {mask_reviews_alta.sum()} produtos (+2.0 pontos)")
    
    # Reviews negativas moderadas (15-30%)
    mask_reviews_media = (df['perc_reviews_negativas'] >= 0.15) & (df['perc_reviews_negativas'] <= 0.30)
    df.loc[mask_reviews_media, 'score_de_suspeita'] += 0.5
    print(f"   üü° Reviews negativas 15-30%: {mask_reviews_media.sum()} produtos (+0.5 ponto)")
    
    # --- 5. INCONSIST√äNCIA XL ---
    print("\nüî§ CRIT√âRIO 10: INCONSIST√äNCIA XL")
    
    mask_xl = df['flag_inconsistencia_xl'] == 1
    df.loc[mask_xl, 'score_de_suspeita'] += 1.0
    print(f"   üü† Inconsist√™ncia XL: {mask_xl.sum()} produtos (+1.0 ponto)")
    
    # --- 6. VENDEDOR NOVO ---
    print("\nüÜï CRIT√âRIO 11: VENDEDOR NOVO")
    
    mask_novo = df['vendedor_total_transacoes'] < 50
    df.loc[mask_novo, 'score_de_suspeita'] += 1.0
    print(f"   üü† Vendedor novo (<50 transa√ß√µes): {mask_novo.sum()} produtos (+1.0 ponto)")
    
    # --- 7. PENALIDADE ESPECIAL: LOJA OFICIAL SUSPEITA ---
    print("\n‚≠ê PENALIDADE ESPECIAL: LOJA OFICIAL COM M√öLTIPLOS CRIT√âRIOS")
    
    # Loja oficial com score >= 2.0 (j√° tem m√∫ltiplos crit√©rios suspeitos)
    mask_loja_oficial_suspeita = (df['e_loja_oficial'] == 1) & (df['score_de_suspeita'] >= 2.0)
    df.loc[mask_loja_oficial_suspeita, 'score_de_suspeita'] += 1.0
    print(f"   üî¥ Loja oficial com m√∫ltiplos crit√©rios: {mask_loja_oficial_suspeita.sum()} produtos (+1.0 ponto)")
    print("   üí° Detecta casos como a loja oficial fraudulenta mencionada pela HP")
    
    # =============================================================================
    # REGRA DE FRAUDE INSTANT√ÇNEA (MANTENDO OUTROS CRIT√âRIOS)
    # =============================================================================
    print("\nüö® APLICANDO REGRA DE FRAUDE INSTANT√ÇNEA...")
    
    # A m√°scara mask_preco_muito_baixo j√° foi definida na se√ß√£o de an√°lise de pre√ßo
    SCORE_INSTANTANEO = 10.0
    
    # CORRE√á√ÉO: Somar em vez de sobrescrever para manter outros crit√©rios
    # Primeiro, remover os 2 pontos j√° adicionados pelo crit√©rio de pre√ßo
    df.loc[mask_preco_muito_baixo, 'score_de_suspeita'] -= 2.0
    # Depois, adicionar o score instant√¢neo
    df.loc[mask_preco_muito_baixo, 'score_de_suspeita'] += SCORE_INSTANTANEO
    # Marcar a flag de fraude instant√¢nea
    df.loc[mask_preco_muito_baixo, 'flag_fraude_instantanea'] = 1
    
    print(f"   ‚úÖ {mask_preco_muito_baixo.sum()} produtos com pre√ßo < -30% tiveram seu score ajustado para {SCORE_INSTANTANEO}")
    print("   üí° Outros crit√©rios (imagem, reputa√ß√£o, etc.) foram mantidos no score final")
    # =============================================================================
    
    # --- 8. CRIAR TARGET BIN√ÅRIO ---
    print("\n" + "="*80)
    print("üéØ DEFININDO THRESHOLD E CRIANDO TARGET")
    print("="*80)
    
    THRESHOLD = 3.0
    df['is_fraud_suspect_v2'] = (df['score_de_suspeita'] >= THRESHOLD).astype(int)
    
    print(f"\nüìä THRESHOLD: {THRESHOLD} pontos")
    print(f"   ‚úÖ Produtos N√ÉO SUSPEITOS (score < {THRESHOLD}): {(df['is_fraud_suspect_v2'] == 0).sum()}")
    print(f"   ‚ö†Ô∏è Produtos SUSPEITOS (score >= {THRESHOLD}): {(df['is_fraud_suspect_v2'] == 1).sum()}")
    print(f"   üìà Taxa de suspeitos: {(df['is_fraud_suspect_v2'] == 1).sum() / len(df) * 100:.1f}%")
    
    # --- 9. AN√ÅLISE DE DISTRIBUI√á√ÉO DE SCORES ---
    print("\nüìä DISTRIBUI√á√ÉO DE SCORES:")
    print("-"*80)
    
    bins = [0, 1, 2, 3, 4, 5, 100]
    labels = ['0-1', '1-2', '2-3', '3-4', '4-5', '5+']
    df['score_faixa'] = pd.cut(df['score_de_suspeita'], bins=bins, labels=labels, include_lowest=True)
    
    distribuicao = df.groupby('score_faixa', observed=True).agg({
        'id_anuncio': 'count',
        'is_fraud_suspect_v2': 'sum'
    }).rename(columns={'id_anuncio': 'total_produtos', 'is_fraud_suspect_v2': 'num_suspeitos'})
    
    for faixa, row in distribuicao.iterrows():
        simbolo = "‚úÖ" if faixa in ['0-1', '1-2', '2-3'] else "‚ö†Ô∏è"
        print(f"   {simbolo} Score {faixa}: {row['total_produtos']:>3} produtos ({row['num_suspeitos']:>2} suspeitos)")
    
    df.drop(columns=['score_faixa'], inplace=True)
    
    print("\n‚úÖ Target 'is_fraud_suspect_v2' criado com sucesso!")
    
    return df

def merge_all_features():
    """Faz merge de todas as features"""
    
    print("\n" + "="*80)
    print("üîó MERGE DE TODAS AS FEATURES")
    print("="*80)
    
    # 1. Carregar Features B√°sicas
    print("\nüìÇ 1. Carregando Features B√°sicas...")
    df_base = pd.read_csv(PATH_FEATURES_BASICAS)
    print(f"   ‚úÖ {len(df_base)} produtos, {len(df_base.columns)} colunas")
    
    # 2. Carregar Reviews NLP
    print("\nüìÇ 2. Carregando Reviews NLP...")
    try:
        df_nlp = pd.read_csv(PATH_REVIEWS_NLP)
        print(f"   ‚úÖ {len(df_nlp)} produtos com reviews, {len(df_nlp.columns)} colunas NLP")
        
        # Merge
        df_merged = pd.merge(df_base, df_nlp, on='id_anuncio', how='left')
        print(f"   ‚úÖ Merge realizado: {len(df_merged)} produtos")
        
        # Preencher NaN para produtos sem reviews
        nlp_cols = [col for col in df_nlp.columns if col != 'id_anuncio']
        for col in nlp_cols:
            if col in df_merged.columns:
                if col.startswith('review_embedding_'):
                    df_merged[col] = df_merged[col].fillna(0.0)
                elif col == 'sentimento_medio_reviews':
                    df_merged[col] = df_merged[col].fillna(0.0)
                else:
                    df_merged[col] = df_merged[col].fillna(0)
        
        print(f"   ‚úÖ NaN preenchidos para produtos sem reviews")
    except FileNotFoundError:
        print("   ‚ö†Ô∏è Arquivo reviews_com_nlp.csv n√£o encontrado. Pulando NLP...")
        df_merged = df_base.copy()
    
    # 3. Carregar Hashes de Imagem
    print("\nüìÇ 3. Carregando Hashes de Imagem...")
    
    # Tentar carregar hashes_imagens_COMPLETO.csv primeiro (m√∫ltiplas imagens)
    hash_file_used = None
    if False:  # PATH_HASHES_COMPLETO n√£o existe mais
        print("   üîç Detectado: hashes_imagens_COMPLETO.csv (m√∫ltiplas imagens)")
        df_hashes = pd.read_csv(PATH_HASHES_COMPLETO)
        hash_file_used = 'COMPLETO'
        
        # Agregar: pegar a contagem M√ÅXIMA de reuso entre todas as imagens do produto
        print("   üìä Agregando m√∫ltiplas imagens por produto (MAX reuso)...")
        df_hashes_agg = df_hashes.groupby('id_anuncio').agg({
            'contagem_reuso_imagem': 'max',  # M√°ximo reuso entre as imagens
            'phash': 'count'  # N√∫mero de imagens
        }).reset_index()
        df_hashes_agg.rename(columns={
            'contagem_reuso_imagem': 'contagem_reuso_imagem',
            'phash': 'num_imagens_produto'
        }, inplace=True)
        
        print(f"   ‚úÖ {len(df_hashes_agg)} produtos com imagens")
        print(f"   üìä M√©dia de imagens por produto: {df_hashes['id_anuncio'].value_counts().mean():.1f}")
        
    elif os.path.exists(PATH_HASHES_IMAGENS):
        print("   üîç Detectado: hashes_imagens.csv (imagem principal)")
        df_hashes_agg = pd.read_csv(PATH_HASHES_IMAGENS)
        hash_file_used = 'SIMPLES'
        df_hashes_agg['num_imagens_produto'] = 1  # Apenas 1 imagem
        print(f"   ‚úÖ {len(df_hashes_agg)} produtos com hash")
    else:
        print("   ‚ö†Ô∏è Nenhum arquivo de hash encontrado. Criando placeholder...")
        df_hashes_agg = pd.DataFrame({
            'id_anuncio': df_merged['id_anuncio'],
            'contagem_reuso_imagem': 1,
            'num_imagens_produto': 0
        })
        hash_file_used = 'PLACEHOLDER'
    
    # Merge hashes
    df_final = pd.merge(df_merged, df_hashes_agg[['id_anuncio', 'contagem_reuso_imagem', 'num_imagens_produto']], 
                        on='id_anuncio', how='left')
    df_final['contagem_reuso_imagem'] = df_final['contagem_reuso_imagem'].fillna(1)
    df_final['num_imagens_produto'] = df_final['num_imagens_produto'].fillna(0)
    
    print(f"   ‚úÖ Merge realizado: {len(df_final)} produtos")
    
    print("\n" + "="*80)
    print("üìä RESUMO DO DATASET MERGED")
    print("="*80)
    print(f"   Total de produtos: {len(df_final)}")
    print(f"   Total de features: {len(df_final.columns)}")
    print(f"   Arquivo de hash usado: {hash_file_used}")
    
    return df_final

def main():
    print("="*80)
    print("üéØ SCRIPT 6: CRIAR TARGET E MERGE FINAL")
    print("="*80)
    
    # 1. Merge de todas as features
    df = merge_all_features()
    
    # 2. Criar target
    df = criar_is_fraud_suspect_v2(df)
    
    # 3. Salvar dataset final
    print("\n" + "="*80)
    print("üíæ SALVANDO DATASET FINAL")
    print("="*80)
    
    df.to_csv(PATH_OUTPUT, index=False)
    print(f"‚úÖ Salvo: {os.path.abspath(PATH_OUTPUT)}")
    print(f"üìä Shape: ({len(df)}, {len(df.columns)})")
    
    # 4. Resumo final
    print("\n" + "="*80)
    print("üìà RESUMO FINAL DO DATASET")
    print("="*80)
    
    print(f"\nüì¶ TOTAL: {len(df)} produtos")
    print(f"üìä FEATURES: {len(df.columns)} colunas")
    print(f"\nüéØ TARGET:")
    print(f"   ‚úÖ N√ÉO SUSPEITOS: {(df['is_fraud_suspect_v2'] == 0).sum()} ({(df['is_fraud_suspect_v2'] == 0).sum() / len(df) * 100:.1f}%)")
    print(f"   ‚ö†Ô∏è SUSPEITOS: {(df['is_fraud_suspect_v2'] == 1).sum()} ({(df['is_fraud_suspect_v2'] == 1).sum() / len(df) * 100:.1f}%)")
    
    print(f"\nüìä SCORE DE SUSPEITA:")
    print(f"   M√≠nimo: {df['score_de_suspeita'].min():.1f}")
    print(f"   M√°ximo: {df['score_de_suspeita'].max():.1f}")
    print(f"   M√©dia: {df['score_de_suspeita'].mean():.1f}")
    print(f"   Mediana: {df['score_de_suspeita'].median():.1f}")
    
    # Lista de features por categoria
    print(f"\nüìã CATEGORIAS DE FEATURES:")
    
    feature_categories = {
        'üî¥ IDENTIFICADORES': [col for col in df.columns if col in ['id_anuncio', 'titulo', 'link_anuncio', 'seller_id', 'vendedor_nome']],
        'üü† PRE√áO': [col for col in df.columns if 'preco' in col.lower() or 'diferenca' in col.lower()],
        'üü° VENDEDOR': [col for col in df.columns if 'vendedor' in col.lower() and col not in ['vendedor_id', 'vendedor_nome']],
        'üü¢ REVIEWS': [col for col in df.columns if 'review' in col.lower() or 'rating' in col.lower()],
        'üîµ PRODUTO': [col for col in df.columns if col in ['tipo_cartucho', 'unidades_por_anuncio', 'cores_detalhadas', 'flag_inconsistencia_xl']],
        'üü£ NLP': [col for col in df.columns if 'sentimento' in col.lower() or 'contagem_' in col.lower() or 'embedding' in col.lower()],
        'üü§ IMAGEM': [col for col in df.columns if 'imagem' in col.lower() or 'phash' in col.lower()],
        '‚ö´ TARGET': [col for col in df.columns if 'fraud' in col.lower() or 'suspeita' in col.lower()]
    }
    
    for categoria, features in feature_categories.items():
        if features:
            print(f"   {categoria}: {len(features)} features")
    
    print("\n" + "="*80)
    print("‚úÖ SCRIPT 4 CONCLU√çDO COM SUCESSO!")
    print("="*80)
    print(f"\nüìÅ Pr√≥ximo passo: Treinar o modelo com {PATH_OUTPUT}")

if __name__ == "__main__":
    main()


